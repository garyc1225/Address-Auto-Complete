{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Address-AutoComplete-Bot\n",
    "\n",
    "This notebook shows the end-to-end process of training and building a Address Autocomplete Bot using Global Attention Mechanism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [1 - Idea](#1)\n",
    "- [2 - Review](#2)\n",
    "- [3 - Address Datasets](#3)\n",
    "    - [3.1 - Training Data Generation](#3-1)\n",
    "    - [3.2 - Data Processing](#3-2)\n",
    "- [4 - Encoder, Attention, and Decoder](#4)\n",
    "    - [4.1 - Encoder](#4-1)\n",
    "    - [4.2 - Attention](#4-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1 - Idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Address is one of the most important pieces of data to get right for all transactions in life. When we input the correct address into a website, we ensure that the products are delivered to the right address, improve customer satisfaction, and reduce the risk of fraud. My wife and I buy hundreds of items across dozens of websites, and it's hard to imagine what would happen if the address was incorrect. Luckily, Google has services like the [Maps API](https://developers.google.com/maps/documentation/javascript), which eliminates these concerns. These map APIs are widely available, lightweight, and easy to deploy. They can be used to build dynamic and interactive maps for web applications using geospatial data, ensuring that customers never enter the wrong address again. For example, the [Place Autocomplete Address Form](https://developers.google.com/maps/documentation/javascript/examples/places-autocomplete-addressform) helps to accurately supply address details. The Place Autocomplete Address Form sample captures selected address components from the Google Places database, and uses them to populate an address form.\n",
    "\n",
    "Recently, I completed the the [Deep Learning Specialization](https://www.deeplearning.ai/courses/deep-learning-specialization/) class from Andrew NG. In this class, I learned about the attention mechanism. The attention mechanism is a powerful neural network technique that has revolutionized the field of Natural Language Processing (NLP). It allows models to focus on specific parts of their input data, which is essential for learning long-range dependencies and understanding the context of complex sequences. Attention mechanisms have been shown to significantly improve the performance of Large Language Models (LLMs) on a variety of tasks, including machine translation, text summarization, and question answering.\n",
    "\n",
    "One question that arises is whether it is possible to train an LLM to predict accurate and complete addresses without requiring any geospatial knowledge. While it is known that LLMs are capable of learning complex and non-linear relationships between features and predictions on tabular data, it is unclear whether they can perform well on address correction (i.e., text generation) without knowing the meaning of individual address components such as street names, cities, and states.\n",
    "\n",
    "This project aims to develop an address autocomplete bot that uses the attention mechanism to autocomplete addresses without requiring any geospatial knowledge. The bot will be trained on a large dataset of correctly formatted addresses, and will use the attention mechanism to learn the relationships between different address components. When given an inaccurate address, the bot will be able to detect the errors and autocomplete the address by filling in missing components or correcting incorrect components.\n",
    "\n",
    "*References: [Effective Approaches to Attention-based Neural Machine Translation (Luong et al., 2015)](https://arxiv.org/abs/1508.04025v5).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "## 2 - Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning methods are being used in solving NLP quesitons since the early 2000s. Deep learning methods are a type of neural network that can learn complex relationships in data. In 2010s, we witness the rise of large language models (LLMs). LLMs are trained on massive datasets of text and code, which allows them to learn the statistical relationships between words and phrases at an unprecedented scale. In the paragraph below, I will summarize the development of deep learning methods on NLP, from Recurrent Neural Network (RNN), Long Short-Term Memory (LSTM), to the recent developed Attention Mechanism. \n",
    "\n",
    "- **Recurrent Neural Networks (RNNs)**\n",
    "\n",
    "RNN are a type of neural network that can process sequences of data. They are the first type of neural networks that are able to learn long-term dependencies within text data, making them the first choice to solve NLP problems. However, one of the disadvantages of RNN is that they are prone to \"vanishing gradient\". The vanishing gradient problem is a major obstacle to training RNNs to learn long-term dependencies. This is because long-term dependencies require the network to remember information from many time steps ago, and the vanishing gradient problem makes it difficult for the network to do this.\n",
    "\n",
    "A language example can easily demonstrate this idea of long-term dependencies. In the sentence below, the verb `has` is influenced by the word `Dog` at the very beginning. If the word `Dog` is changed to a plural form, then the verb `has` would need to be updated to the word `have`. This long-range dependencies can extend over a very long step, as we do not know how many words (aka steps) are in between these two words.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"image/language_example.png\" width=\"500\"> <br>\n",
    "<caption><center><b>Figure 1</b>: A language example </center></caption>\n",
    "</div>\n",
    "\n",
    "A standard RNN neural network architecture is shown below. In order to learn the long-term dependencies relationship, we hope the model is able to pass on the hidden state $a^{\\langle 2 \\rangle}$ to the position of $x^{\\langle T_{x} \\rangle}$. The basic RNNs that we have seen so far are not very good at handling such long-term dependencies, mainly due to the Vanishing Gradient Problem. When the gradients traverse through multiple steps it become very small, which makes it difficult for the network to learn.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"image/rnn.png\" width=\"500\"> <br>\n",
    "<caption><center><b>Figure 2</b>: Basic RNN Structure </center></caption>\n",
    "</div>\n",
    "\n",
    "- **Long Short-Term Memory (LSTM)**\n",
    "\n",
    "LSTMs are a type of RNN that address the vanishing gradient problem. They do this by using gates to control the flow of information in the network. The figure below shows the operations of an LSTM cell.\n",
    "\n",
    "The gates in a LSTM cell are described below:\n",
    "\n",
    "- Forget Gate ($\\mathbf{\\Gamma}_{f}$): The forget gate can be used to *\"forget\"* the previous state. For example, if the subject changes from a singular word `Dog` to a plural `Dogs`, the memory of the previous state becomes outdated and should be forgotten. \n",
    "\n",
    "- Update Gate ($\\mathbf{\\Gamma}_{i}$): The update gate can be used to decide what aspects of the candidate $\\tilde{\\mathbf{c}}^{\\langle t \\rangle}$ to add to the cell state $c^{\\langle t \\rangle}$. The candidate $\\tilde{\\mathbf{c}}^{\\langle t \\rangle}$ is a tensor containing information from the current time step that **may** be stored in the current cell state $\\mathbf{c}^{\\langle t \\rangle}$. The current cell state $\\mathbf{c}^{\\langle t \\rangle}$ is the \"memory\" that gets passed onto future time steps.\n",
    "\n",
    "- Output Gate ($\\mathbf{\\Gamma}_{o}$): The output gate decides what gets sent as the prediction (output) of the time step.\n",
    "\n",
    "The LSTM unit can remember long-term dependencies because the cell state is not updated at every time step, as shown in formula 4. This allows the LSTM unit to retain information from previous time steps, even if it is not used in the current time step.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"image/lstm.png\" width=\"500\"> <br>\n",
    "<caption><center><b>Figure 3</b>: LSTM Cell </center></caption>\n",
    "</div>\n",
    "\n",
    "$$\\mathbf{\\Gamma}_f^{\\langle t \\rangle} = \\sigma(\\mathbf{W}_f[\\mathbf{a}^{\\langle t-1 \\rangle}, \\mathbf{x}^{\\langle t \\rangle}] + \\mathbf{b}_f)\\tag{1} $$\n",
    "$$\\mathbf{\\Gamma}_i^{\\langle t \\rangle} = \\sigma(\\mathbf{W}_i[a^{\\langle t-1 \\rangle}, \\mathbf{x}^{\\langle t \\rangle}] + \\mathbf{b}_i)\\tag{2} $$ \n",
    "$$\\mathbf{\\tilde{c}}^{\\langle t \\rangle} = \\tanh\\left( \\mathbf{W}_{c} [\\mathbf{a}^{\\langle t - 1 \\rangle}, \\mathbf{x}^{\\langle t \\rangle}] + \\mathbf{b}_{c} \\right) \\tag{3}$$\n",
    "$$ \\mathbf{c}^{\\langle t \\rangle} = \\mathbf{\\Gamma}_f^{\\langle t \\rangle}* \\mathbf{c}^{\\langle t-1 \\rangle} + \\mathbf{\\Gamma}_{i}^{\\langle t \\rangle} *\\mathbf{\\tilde{c}}^{\\langle t \\rangle} \\tag{4} $$\n",
    "$$ \\mathbf{\\Gamma}_o^{\\langle t \\rangle}=  \\sigma(\\mathbf{W}_o[\\mathbf{a}^{\\langle t-1 \\rangle}, \\mathbf{x}^{\\langle t \\rangle}] + \\mathbf{b}_{o})\\tag{5}$$ \n",
    "$$ \\mathbf{a}^{\\langle t \\rangle} = \\mathbf{\\Gamma}_o^{\\langle t \\rangle} * \\tanh(\\mathbf{c}^{\\langle t \\rangle})\\tag{6} $$\n",
    "\n",
    "- **Attention Mechanism**\n",
    "\n",
    "LSTM solves the vanishing gradient problem as it allows the cell state to flow through multiple time steps. However, in the language example above, the word `has` does not rely on any other word in the sentence other than the word `dog`. Attention Mechanism was developed to allow the neural network to put more weight on certain long-range dependencies than others at each position $x^{\\langle T_{x} \\rangle}$, hence the word \"Attention\".\n",
    "\n",
    "The attention mechanism was first proposed by __[Neural Machine Translation by Jointly Learning to Align and Translate (Bahdanau et al., 2014)](https://arxiv.org/abs/1409.0473)__, and its a powerful tool that has revolutionized the field of NLP.  Attention Mechanism is commonly used with the encoder-decoders network family. The encoder encodes a source sentence into a fixed-length tensor. The attention mechanism then calcualtes a score for each word, indicating how important the word is to the current position $x^{\\langle T_{x} \\rangle}$. When the score is higher, the network will pay more attention to this word for the current output $y^{\\langle T_{x} \\rangle}$. When the score is lower, the network pay less attention.\n",
    "\n",
    "The figure below shows what one \"attention\" step does to calculate the attention variables $\\alpha^{\\langle t, t' \\rangle}$. $s^{\\langle t-1 \\rangle}$ is the one-step prior hidden state from the post-attention decoder, and $a^{\\langle t' \\rangle}$ is the hidden state from the pre-attention encoder. $s^{\\langle t-1 \\rangle}$ and $a^{\\langle t \\rangle}$ are fed into a simple neural network with a dense layer to learn and compute the output $e^{\\langle t, t' \\rangle}$. $e^{\\langle t, t' \\rangle}$ is then used when computing the attention $\\alpha^{\\langle t, t' \\rangle}$ that $y^{\\langle t \\rangle}$ should pay to $a^{\\langle t' \\rangle}$. \n",
    "\n",
    "Finally, the $context^{ \\langle t \\rangle }$ works as a weighted average of all the attention weights. Then, the decoder's output along with the context vector is used to predict the next output $y^{\\langle T_{x+1} \\rangle}$\n",
    "\n",
    "$$context^{<t>} = \\sum_{t' = 1}^{T_x} \\alpha^{<t,t'>}a^{<t'>}\\tag{1}$$ \n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"image/attn_mechanism.png\" width=\"500\"> <br>\n",
    "<caption><center><b>Figure 4</b>: Attention Mechanism </center></caption>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "## 3 - Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The address data is downloaded from the [New York State Geographic Information System (GIS)](https://gis.ny.gov/) website. We will only train this bot on the larger NY area addresses (Manhattan, Brooklyn, Queens, Bronx, Staten Island) for demonstration purpose and to minimize network training time.\n",
    "The address dataset download direction can be found [here](https://gis.ny.gov/system/files/documents/2023/03/how-to-create-county-filters-of-nys-address-point-data.pdf).\n",
    "\n",
    "The dataset has the below columns: \n",
    "\n",
    "|**Column Name**|**Type**|\n",
    "|------|------|\n",
    "|AddressNumber|int|\n",
    "|StreetName|string|\n",
    "|PostType|string|\n",
    "|CountyName|string|\n",
    "|CityTownName|string|\n",
    "|ZipName|string|\n",
    "|ZipCode|int|\n",
    "|State|string|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gkchen\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as tf_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (746396, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AddressNumber</th>\n",
       "      <th>StreetName</th>\n",
       "      <th>PostType</th>\n",
       "      <th>CountyName</th>\n",
       "      <th>CityTownName</th>\n",
       "      <th>ZipName</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5310541</th>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>Ave</td>\n",
       "      <td>Queens</td>\n",
       "      <td>New York</td>\n",
       "      <td>Corona</td>\n",
       "      <td>11368</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4351709</th>\n",
       "      <td>9</td>\n",
       "      <td>125</td>\n",
       "      <td>St</td>\n",
       "      <td>Queens</td>\n",
       "      <td>New York</td>\n",
       "      <td>South Richmond Hill</td>\n",
       "      <td>11419</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5410919</th>\n",
       "      <td>321</td>\n",
       "      <td>34</td>\n",
       "      <td>St</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>10016</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5399431</th>\n",
       "      <td>430</td>\n",
       "      <td>84</td>\n",
       "      <td>St</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>10028</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5507966</th>\n",
       "      <td>742</td>\n",
       "      <td>43</td>\n",
       "      <td>St</td>\n",
       "      <td>Kings</td>\n",
       "      <td>New York</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>11203</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         AddressNumber StreetName PostType CountyName CityTownName  \\\n",
       "5310541             64         50      Ave     Queens     New York   \n",
       "4351709              9        125       St     Queens     New York   \n",
       "5410919            321         34       St   New York     New York   \n",
       "5399431            430         84       St   New York     New York   \n",
       "5507966            742         43       St      Kings     New York   \n",
       "\n",
       "                     ZipName  ZipCode State  \n",
       "5310541               Corona    11368    NY  \n",
       "4351709  South Richmond Hill    11419    NY  \n",
       "5410919             New York    10016    NY  \n",
       "5399431             New York    10028    NY  \n",
       "5507966             Brooklyn    11203    NY  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ny_address = pd.read_parquet('Datasets/NYS_clean.parquet.gz', engine='pyarrow')\n",
    "print(f'Dataset shape: {ny_address.shape}')\n",
    "ny_address.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Kings          0.386011\n",
       "Queens         0.234193\n",
       "Richmond       0.166930\n",
       "Bronx          0.136503\n",
       "New York       0.076250\n",
       "Nassau         0.000074\n",
       "Westchester    0.000039\n",
       "Name: CountyName, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the County Distribution: 62% of the addresses are in Kings (Brooklyn borough) and Quees (Queens borough) county.\n",
    "ny_address['CountyName'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AddressNumber has max length of 5\n",
      "StreetName has max length of 28\n",
      "PostType has max length of 6\n",
      "CountyName has max length of 11\n",
      "CityTownName has max length of 8\n",
      "ZipName has max length of 19\n",
      "ZipCode has max length of 5\n",
      "State has max length of 2\n"
     ]
    }
   ],
   "source": [
    "# Checking the length for each address component. Max word length is an important parameter for the word embedding that will happen later\n",
    "for col_i in ny_address.columns:\n",
    "    print(f'{col_i} has max length of {ny_address[col_i].astype(str).apply(len).max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3-1\"></a>\n",
    "## 3-1 - Training Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gkchen\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "from importlib import reload\n",
    "utils = reload(utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the neural network to output the correct complete address, we need to teach it the relationships between different address components. To do this, we generate training data by \"masking\" certain address components. The `context_raw` dataframe contains the \"masked\" addresses, and the `target_raw` dataframe contains the complete addresses. We sample with replacement so that one address can be used for multiple training data points.\n",
    "\n",
    "The figure below illustrates the training data generation process. For example, if we mask one complete address three different ways, we will generate three training data points.\n",
    "\n",
    "One limitation of this method is that not all training data points are equally helpful to the model. This is because the address components have a hierarchical structure. For example, training data point No. 3 will be helpful to the model because we want it to learn to output the most likely zip code for `321 34th St, New York, New York`, which is `10016`. However, training data point No. 1 will not be as helpful, because many addresses can have the zip code `10016`. We expect the model cost function to reduce with training data point No. 3, but not so much with training data point No. 1. \n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"image/mask_generate.PNG\" width=\"800\"> <br>\n",
    "<caption><center><b>Figure 5</b>: Training Data Generation Process </center></caption>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context shape: (2000000,)\n",
      "Target shape: (2000000,)\n"
     ]
    }
   ],
   "source": [
    "context_raw,target_raw = utils.create_label_target('Datasets/NYS_clean.parquet.gz')\n",
    "print(f'Context shape: {context_raw.shape}')\n",
    "print(f'Target shape: {target_raw.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked Address: 4015 Church Kings NY 11203\n",
      "Complete Address: 4015 Church Ave Brooklyn Kings NY 11203\n"
     ]
    }
   ],
   "source": [
    "random_numbers = np.random.choice(len(context_raw), 1)[0]\n",
    "print(f'Masked Address: {context_raw[random_numbers]}')\n",
    "print(f'Complete Address: {target_raw[random_numbers]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"Datasets/context_raw.npy\", context_raw)\n",
    "# np.save(\"Datasets/target_raw.npy\", target_raw)\n",
    "\n",
    "context_raw = np.load(\"Datasets/context_raw.npy\")\n",
    "target_raw = np.load(\"Datasets/target_raw.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3-2\"></a>\n",
    "## 3-2 - Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**: Split the dataset into 80% `train_raw` and 20% `val_raw`. Create a `tf.data.Dataset` for these strings. `tf.data.Dataset` is designed to be efficient, both in terms of memory usage and runtime performance. It can automatically parallelize data loading and processing, and it can also be used to cache data in memory or on disk to improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_text as tf_text\n",
    "\n",
    "BUFFER_SIZE = len(context_raw)\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "is_train = np.random.uniform(size=(len(target_raw),)) < 0.8\n",
    "\n",
    "train_raw = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((context_raw[is_train], target_raw[is_train]))\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE))\n",
    "val_raw = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((context_raw[~is_train], target_raw[~is_train]))\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**: We can use the `tf.keras.layers.TextVectorization` to apply preprocessing to the text, and maps text features to integer token sequences. The text standardization is handled by the `utils.tf_lower_and_split_punct`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This parameters defines the saximum size of the vocabulary for this layer\n",
    "max_vocab_size = 5000\n",
    "\n",
    "context_text_processor = tf.keras.layers.TextVectorization(\n",
    "    standardize=utils.tf_lower_and_split_punct,\n",
    "    max_tokens=max_vocab_size,\n",
    "    ragged=True)\n",
    "\n",
    "# The adapt method reads one epoch of the training data, and works a lot like Model.fit. This method initializes the layer based on the data.\n",
    "context_text_processor.adapt(train_raw.map(lambda context, target: context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_text_processor = tf.keras.layers.TextVectorization(\n",
    "    standardize=utils.tf_lower_and_split_punct,\n",
    "    max_tokens=max_vocab_size,\n",
    "    ragged=True)\n",
    "\n",
    "target_text_processor.adapt(train_raw.map(lambda context, target: target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Address To token: [  2 141 218   5   7   6   4 128   3]\n",
      "Token back to Address\n",
      "[START] 68 96 st brooklyn kings ny 11212 [END]\n"
     ]
    }
   ],
   "source": [
    "# The context_text_processor convert a address into a token sequences\n",
    "# The [START] and [END] represents the Start of String token and End of String token. These tokens will tell the model when to start and stop the prediction.\n",
    "example_text = tf.constant('68 96 St Brooklyn Kings NY 11212')\n",
    "example_tokens = context_text_processor(example_text)\n",
    "print(f'Address To token: {example_tokens}')\n",
    "\n",
    "context_vocab = np.array(context_text_processor.get_vocabulary())\n",
    "tokens = context_vocab[example_tokens.numpy()]\n",
    "print('Token back to Address')\n",
    "print(' '.join(tokens))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3**: Convert the `tf.data.Dataset` to 0-padded tensors of token. The `target_in` and `target_out` is shifted by one step relative to each other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(context, target):\n",
    "    context = context_text_processor(context).to_tensor()\n",
    "    target = target_text_processor(target)\n",
    "    targ_in = target[:,:-1].to_tensor()\n",
    "    targ_out = target[:,1:].to_tensor()\n",
    "    return (context, targ_in), targ_out\n",
    "\n",
    "train_ds = train_raw.map(process_text, tf.data.AUTOTUNE)\n",
    "val_ds = val_raw.map(process_text, tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.Dataset.save(train_ds, \"Datasets/train_ds.tfds\")\n",
    "tf.data.Dataset.save(val_ds, \"Datasets/val_ds.tfds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "# 4 - Encoder, Attention, and Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4-1\"></a>\n",
    "## 4-1 - Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the encoder is to process the context sequence $x^{\\langle T_{x} \\rangle}$ (in our case, the address string) into a sequence of vectors that the decoder can use to predict the next output $y^{\\langle T_{x+1} \\rangle}$.\n",
    "<br>\n",
    "<br>\n",
    "The details of the encoder network is listed below:\n",
    "\n",
    "1. `tf.keras.layers.Embedding`: An embedding layer that convert postive integers (i.e., tokens) into dense vectors\n",
    "\n",
    "2. `tf.keras.layers.Bidirectional`: A bi-directional wrapper for RNNs. Here we use a LSTM unit with 256 neurons. The reason we choose a bi-directional LSTM is because the hidden state should flow both ways in the encoder. For example, in the exmample address of `4015 Church Ave Brooklyn Kings NY 11203`, the borough component `Brooklyn` should have the hidden state flow from the prior component `4015 Church Ave` and also from the post component `Kings NY 11203`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNITS = 256\n",
    "\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, text_processor, units):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.text_processor = text_processor\n",
    "        self.vocab_size = text_processor.vocabulary_size()\n",
    "        self.units = units\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(self.vocab_size, units, mask_zero=True)\n",
    "\n",
    "        self.rnn = tf.keras.layers.Bidirectional(\n",
    "            merge_mode='sum',\n",
    "            layer=tf.keras.layers.LSTM(units,return_sequences=True))\n",
    "\n",
    "    def call(self, x):\n",
    "        shape_checker = utils.ShapeChecker()\n",
    "        shape_checker(x, 'batch s')\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        shape_checker(x, 'batch s units')\n",
    "\n",
    "        x = self.rnn(x)\n",
    "        shape_checker(x, 'batch s units')\n",
    "\n",
    "        return x\n",
    "\n",
    "    def convert_input(self, texts):\n",
    "        texts = tf.convert_to_tensor(texts)\n",
    "        if len(texts.shape) == 0:\n",
    "          texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
    "        context = self.text_processor(texts).to_tensor()\n",
    "        context = self(context)\n",
    "        return context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4-2\"></a>\n",
    "## 4-2 - Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attention layer allows the decoder to access the information extracted by the encoder. It computes a `context vector` from the entire context sequence, and adds that to the decoder's output.\n",
    "<br>\n",
    "<br>\n",
    "The details of the attention layer is listed below:\n",
    "\n",
    "1. `tf.keras.layers.MultiHeadAttention`: A single head attention layer (num_heads = 1). The `key_dim` is set to 256. This means the attention head for the `query` and `key` will have dimension = 256.\n",
    "\n",
    "* The components of the attention layer is specified here:\n",
    "    * (`Batch`, $m$): Number of records in each batch  \n",
    "    * (`t`, $t$): Target dimension\n",
    "    * (`s`, $s$): Source dimension\n",
    "    * (`heads`, $h$): Number of attention heads\n",
    "    * (`units`, $dim$): Number of hidden units from the LSTM layer\n",
    "\n",
    "* The matrices dimension for each attention component:\n",
    "    * `Query`:  ($m$,$t$,$dim$)\n",
    "    * `Value`:  ($m$,$s$,$dim$)\n",
    "    * `Attention Output`: ?\n",
    "    * `Attention Score (before average across heads)`: ($m$, $h$, $t$, $s$)\n",
    "    * `Attention Score (after average across heads)`: ($m$, $t$, $s$)\n",
    "\n",
    "2. `tf.keras.layers.Add`: Concatting the attention output along with the input `X`\n",
    "\n",
    "3. `tf.keras.layers.LayerNormalization`: Normalize the activations of the previous layer for each given example in a batch independently, not across examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super().__init__()\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n",
    "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "        self.add = tf.keras.layers.Add()\n",
    "\n",
    "    def call(self, x, context):\n",
    "        shape_checker = utils.ShapeChecker()\n",
    "\n",
    "        shape_checker(x, 'batch t units')\n",
    "        shape_checker(context, 'batch s units')\n",
    "\n",
    "        attn_output, attn_scores = self.mha(\n",
    "            query=x,\n",
    "            value=context,\n",
    "            return_attention_scores=True)\n",
    "\n",
    "        shape_checker(x, 'batch t units')\n",
    "        shape_checker(attn_scores, 'batch heads t s')\n",
    "\n",
    "        attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
    "        shape_checker(attn_scores, 'batch t s')\n",
    "        self.last_attention_weights = attn_scores\n",
    "\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layernorm(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4-3\"></a>\n",
    "## 4-3 - Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the decoder is to generate predictions for the next token at each location in the target sequence.\n",
    "<br>\n",
    "<br>\n",
    "The details of the decoder is listed below:\n",
    "\n",
    "1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    @classmethod\n",
    "    def add_method(cls, fun):\n",
    "        setattr(cls, fun.__name__, fun)\n",
    "        return fun\n",
    "\n",
    "    def __init__(self, text_processor, units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.text_processor = text_processor\n",
    "        self.vocab_size = text_processor.vocabulary_size()\n",
    "        self.word_to_id = tf.keras.layers.StringLookup(\n",
    "            vocabulary=text_processor.get_vocabulary(),\n",
    "            mask_token='', oov_token='[UNK]')\n",
    "        self.id_to_word = tf.keras.layers.StringLookup(\n",
    "            vocabulary=text_processor.get_vocabulary(),\n",
    "            mask_token='', oov_token='[UNK]',\n",
    "            invert=True)\n",
    "        self.start_token = self.word_to_id('[START]')\n",
    "        self.end_token = self.word_to_id('[END]')\n",
    "\n",
    "        self.units = units\n",
    "\n",
    "\n",
    "        # 1. The embedding layer converts token IDs to vectors\n",
    "        self.embedding = tf.keras.layers.Embedding(self.vocab_size,\n",
    "                                                units, mask_zero=True)\n",
    "\n",
    "        # 2. The RNN keeps track of what's been generated so far.\n",
    "        self.rnn = tf.keras.layers.GRU(units,\n",
    "                                    return_sequences=True,\n",
    "                                    return_state=True,\n",
    "                                    recurrent_initializer='glorot_uniform')\n",
    "\n",
    "        # 3. The RNN output will be the query for the attention layer.\n",
    "        self.attention = CrossAttention(units)\n",
    "\n",
    "        # 4. This fully connected layer produces the logits for each\n",
    "        # output token.\n",
    "        self.output_layer = tf.keras.layers.Dense(self.vocab_size)\n",
    "\n",
    "@Decoder.add_method\n",
    "def call(self,\n",
    "         context, x,\n",
    "         state=None,\n",
    "         return_state=False):  \n",
    "    shape_checker = utils.ShapeChecker()\n",
    "    shape_checker(x, 'batch t')\n",
    "    shape_checker(context, 'batch s units')\n",
    "\n",
    "    # 1. Lookup the embeddings\n",
    "    x = self.embedding(x)\n",
    "    shape_checker(x, 'batch t units')\n",
    "\n",
    "    # 2. Process the target sequence.\n",
    "    x, state = self.rnn(x, initial_state=state)\n",
    "    shape_checker(x, 'batch t units')\n",
    "\n",
    "    # 3. Use the RNN output as the query for the attention over the context.\n",
    "    x = self.attention(x, context)\n",
    "    self.last_attention_weights = self.attention.last_attention_weights\n",
    "    shape_checker(x, 'batch t units')\n",
    "    shape_checker(self.last_attention_weights, 'batch t s')\n",
    "\n",
    "    # Step 4. Generate logit predictions for the next token.\n",
    "    logits = self.output_layer(x)\n",
    "    shape_checker(logits, 'batch t target_vocab_size')\n",
    "\n",
    "    if return_state:\n",
    "        return logits, state\n",
    "    else:\n",
    "        return logits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
