{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Address-AutoComplete-Bot\n",
    "\n",
    "This notebook shows the end-to-end process of training and building a Address Autocomplete Bot using Global Attention Mechanism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [1 - Intro](#1)\n",
    "- [2 - Review](#2)\n",
    "- [3 - Address Datasets](#3)\n",
    "    - [3.1 - Training Data Generation](#3-1)\n",
    "    - [3.2 - Data Processing](#3-2)\n",
    "- [4 - Encoder, Attention, and Decoder](#4)\n",
    "    - [4.1 - Encoder](#4-1)\n",
    "    - [4.2 - Attention](#4-2)\n",
    "    - [4.3 - Decoder](#4-3)\n",
    "    - [4.4 - Shape Check](#4-4)\n",
    "- [5 - Training](#5)\n",
    "- [6 - Inference](#6)\n",
    "    - [6.1 - Deep Dive](#4-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1 - Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine the chaos of online shopping if addresses were a crapshoot. Wrong deliveries, frustrated customers, and the fraud that could totally ruin our holidays. Address is one of the most important data to get right for all transactions in life. My wife and I buy countless items across dozens of websites, and it's hard to imagine what would happen if the address was incorrect. Luckily this is not a hard problem: we have powerful tools like [Google Maps API](https://developers.google.com/maps/documentation/javascript) to ensure address accuracy. But, are geospatial databases the only way to go?\n",
    "\n",
    "Recently, I completed the [Deep Learning Specialization](https://www.deeplearning.ai/courses/deep-learning-specialization/) course from Andrew NG. During the course of Large Language Models (LLM), I dove into the heart of all advanced sequenced models - attention mechanism. The attention mechanism is a powerful algorithm that has revolutionized the field of Natural Language Processing (NLP). It allows models to focus on specific parts of their input data, which is essential for learning long-range dependencies and understanding the context of complex sequences. Attention mechanisms have been shown to significantly improve the performance of Large Language Models (LLMs) on a variety of tasks, including machine translation, text summarization, and question answering.\n",
    "\n",
    "My question: **Can a toy-size LLM demonstrate good performance on the task of predicting accurate and auto-complete addresses without any geospatial knowledge?** While it is known that LLMs are capable of learning complex and non-linear relationships between features and predictions on tabular & text data, it is unclear whether they can perform well on address correction (i.e., text generation) without knowing the representative meaning of individual address components such as street names, cities, and states. Can they correctly predict that an address should be in New York, without knowing what the text \"New York\" mean?\n",
    "\n",
    "This toy project aims to develop an address autocomplete bot that uses the attention mechanism to autocomplete addresses without requiring any geospatial knowledge. The bot will be trained on a large dataset of correctly formatted addresses, and will use the attention mechanism to learn the relationships between different address components. The address autocomplete bot will be able to do things:\n",
    "  1. **Detect Address Error**: When given an inaccurate address, the bot will be able to detect the errors and modify the output address\n",
    "  2. **Autocomplet Address**: When given an inomplete address, the bot will be able to autocomplete the remaining address.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"image/bot_function_1.png\" width=\"500\"> <br>\n",
    "<caption><center><b>Figure 0</b>: Address AutoComplete Bot Function </center></caption>\n",
    "</div>\n",
    "\n",
    "*References*\n",
    "  - [Effective Approaches to Attention-based Neural Machine Translation (Luong et al., 2015)](https://arxiv.org/abs/1508.04025v5)\n",
    "  - [Neural Machine Translation with attention](https://www.tensorflow.org/text/tutorials/nmt_with_attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "## 2 - Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning methods are being used in solving NLP quesitons since the early 2000s. Deep learning methods are a type of neural network that can learn complex relationships in data. In 2010s, we witness the rise of large language models (LLMs). LLMs are trained on massive datasets of text and code, which allows them to learn the statistical relationships between words and phrases at an unprecedented scale. In the paragraph below, I will summarize the development of deep learning methods on NLP, from Recurrent Neural Network (RNN), Long Short-Term Memory (LSTM), to the recent developed Attention Mechanism. \n",
    "\n",
    "- **Recurrent Neural Networks (RNNs)**\n",
    "\n",
    "RNN are a type of neural network that can process sequences of data. They are the first type of neural networks that are able to learn long-term dependencies within text data, making them the first choice to solve NLP problems. However, one of the disadvantages of RNN is that they are prone to \"vanishing gradient\". The vanishing gradient problem is a major obstacle to training RNNs to learn long-term dependencies. This is because long-term dependencies require the network to remember information from many time steps ago, and the vanishing gradient problem makes it difficult for the network to do this.\n",
    "\n",
    "A language example can easily demonstrate this idea of long-term dependencies. In the sentence below, the verb `has` is influenced by the word `Dog` at the very beginning. If the word `Dog` is changed to a plural form, then the verb `has` would need to be updated to the word `have`. This long-range dependencies can extend over a very long step, as we do not know how many words (aka steps) are in between these two words.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"image/language_example.png\" width=\"500\"> <br>\n",
    "<caption><center><b>Figure 1</b>: A language example </center></caption>\n",
    "</div>\n",
    "\n",
    "A standard RNN neural network architecture is shown below. In order to learn the long-term dependencies relationship, we hope the model is able to pass on the hidden state $a^{\\langle 2 \\rangle}$ to the position of $x^{\\langle T_{x} \\rangle}$. The basic RNNs that we have seen so far are not very good at handling such long-term dependencies, mainly due to the Vanishing Gradient Problem. When the gradients traverse through multiple steps it become very small, which makes it difficult for the network to learn.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"image/rnn.png\" width=\"500\"> <br>\n",
    "<caption><center><b>Figure 2</b>: Basic RNN Structure </center></caption>\n",
    "</div>\n",
    "\n",
    "- **Long Short-Term Memory (LSTM)**\n",
    "\n",
    "LSTMs are a type of RNN that address the vanishing gradient problem. They do this by using gates to control the flow of information in the network. The figure below shows the operations of an LSTM cell.\n",
    "\n",
    "The gates in a LSTM cell are described below:\n",
    "\n",
    "- Forget Gate ($\\mathbf{\\Gamma}_{f}$): The forget gate can be used to *\"forget\"* the previous state. For example, if the subject changes from a singular word `Dog` to a plural `Dogs`, the memory of the previous state becomes outdated and should be forgotten. \n",
    "\n",
    "- Update Gate ($\\mathbf{\\Gamma}_{i}$): The update gate can be used to decide what aspects of the candidate $\\tilde{\\mathbf{c}}^{\\langle t \\rangle}$ to add to the cell state $c^{\\langle t \\rangle}$. The candidate $\\tilde{\\mathbf{c}}^{\\langle t \\rangle}$ is a tensor containing information from the current time step that **may** be stored in the current cell state $\\mathbf{c}^{\\langle t \\rangle}$. The current cell state $\\mathbf{c}^{\\langle t \\rangle}$ is the \"memory\" that gets passed onto future time steps.\n",
    "\n",
    "- Output Gate ($\\mathbf{\\Gamma}_{o}$): The output gate decides what gets sent as the prediction (output) of the time step.\n",
    "\n",
    "The LSTM unit can remember long-term dependencies because the cell state is not updated at every time step, as shown in formula 4. This allows the LSTM unit to retain information from previous time steps, even if it is not used in the current time step.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"image/lstm.png\" width=\"500\"> <br>\n",
    "<caption><center><b>Figure 3</b>: LSTM Cell </center></caption>\n",
    "</div>\n",
    "\n",
    "$$\\mathbf{\\Gamma}_f^{\\langle t \\rangle} = \\sigma(\\mathbf{W}_f[\\mathbf{a}^{\\langle t-1 \\rangle}, \\mathbf{x}^{\\langle t \\rangle}] + \\mathbf{b}_f)\\tag{1} $$\n",
    "$$\\mathbf{\\Gamma}_i^{\\langle t \\rangle} = \\sigma(\\mathbf{W}_i[a^{\\langle t-1 \\rangle}, \\mathbf{x}^{\\langle t \\rangle}] + \\mathbf{b}_i)\\tag{2} $$ \n",
    "$$\\mathbf{\\tilde{c}}^{\\langle t \\rangle} = \\tanh\\left( \\mathbf{W}_{c} [\\mathbf{a}^{\\langle t - 1 \\rangle}, \\mathbf{x}^{\\langle t \\rangle}] + \\mathbf{b}_{c} \\right) \\tag{3}$$\n",
    "$$ \\mathbf{c}^{\\langle t \\rangle} = \\mathbf{\\Gamma}_f^{\\langle t \\rangle}* \\mathbf{c}^{\\langle t-1 \\rangle} + \\mathbf{\\Gamma}_{i}^{\\langle t \\rangle} *\\mathbf{\\tilde{c}}^{\\langle t \\rangle} \\tag{4} $$\n",
    "$$ \\mathbf{\\Gamma}_o^{\\langle t \\rangle}=  \\sigma(\\mathbf{W}_o[\\mathbf{a}^{\\langle t-1 \\rangle}, \\mathbf{x}^{\\langle t \\rangle}] + \\mathbf{b}_{o})\\tag{5}$$ \n",
    "$$ \\mathbf{a}^{\\langle t \\rangle} = \\mathbf{\\Gamma}_o^{\\langle t \\rangle} * \\tanh(\\mathbf{c}^{\\langle t \\rangle})\\tag{6} $$\n",
    "\n",
    "- **Attention Mechanism**\n",
    "\n",
    "LSTM solves the vanishing gradient problem as it allows the cell state to flow through multiple time steps. However, in the language example above, the word `has` does not rely on any other word in the sentence other than the word `dog`. Attention Mechanism was developed to allow the neural network to put more weight on certain long-range dependencies than others at each position $x^{\\langle T_{x} \\rangle}$, hence the word \"Attention\".\n",
    "\n",
    "The attention mechanism was first proposed by __[Neural Machine Translation by Jointly Learning to Align and Translate (Bahdanau et al., 2014)](https://arxiv.org/abs/1409.0473)__, and its a powerful tool that has revolutionized the field of NLP.  Attention Mechanism is commonly used with the encoder-decoders network family. The encoder encodes a source sentence into a fixed-length tensor. The attention mechanism then calcualtes a score for each word, indicating how important the word is to the current position $x^{\\langle T_{x} \\rangle}$. When the score is higher, the network will pay more attention to this word for the current output $y^{\\langle T_{x} \\rangle}$. When the score is lower, the network pay less attention.\n",
    "\n",
    "The figure below shows what one \"attention\" step does to calculate the attention variables $\\alpha^{\\langle t, t' \\rangle}$. $s^{\\langle t-1 \\rangle}$ is the one-step prior hidden state from the post-attention decoder, and $a^{\\langle t' \\rangle}$ is the hidden state from the pre-attention encoder. $s^{\\langle t-1 \\rangle}$ and $a^{\\langle t \\rangle}$ are fed into a simple neural network with a dense layer to learn and compute the output $e^{\\langle t, t' \\rangle}$. $e^{\\langle t, t' \\rangle}$ is then used when computing the attention $\\alpha^{\\langle t, t' \\rangle}$ that $y^{\\langle t \\rangle}$ should pay to $a^{\\langle t' \\rangle}$. \n",
    "\n",
    "Finally, the $context^{ \\langle t \\rangle }$ works as a weighted average of all the attention weights. Then, the decoder's output along with the context vector is used to predict the next output $y^{\\langle T_{x+1} \\rangle}$\n",
    "\n",
    "$$context^{<t>} = \\sum_{t' = 1}^{T_x} \\alpha^{<t,t'>}a^{<t'>}\\tag{1}$$ \n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"image/attn_mechanism.png\" width=\"500\"> <br>\n",
    "<caption><center><b>Figure 4</b>: Attention Mechanism </center></caption>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "## 3 - Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The address data is downloaded from the [New York State Geographic Information System (GIS)](https://gis.ny.gov/) website. We will only train this bot on the larger NY area addresses (Manhattan, Brooklyn, Queens, Bronx, Staten Island) for demonstration purpose and to minimize network training time. The address dataset download direction can be found [here](https://gis.ny.gov/system/files/documents/2023/03/how-to-create-county-filters-of-nys-address-point-data.pdf).\n",
    "\n",
    "The dataset has the below columns: \n",
    "\n",
    "|**Column Name**|**Type**|\n",
    "|------|------|\n",
    "|AddressNumber|int|\n",
    "|StreetName|string|\n",
    "|PostType|string|\n",
    "|CountyName|string|\n",
    "|CityTownName|string|\n",
    "|ZipName|string|\n",
    "|ZipCode|int|\n",
    "|State|string|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gkchen\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as tf_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (746396, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AddressNumber</th>\n",
       "      <th>StreetName</th>\n",
       "      <th>PostType</th>\n",
       "      <th>CountyName</th>\n",
       "      <th>CityTownName</th>\n",
       "      <th>ZipName</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5671799</th>\n",
       "      <td>1468</td>\n",
       "      <td>53</td>\n",
       "      <td>St</td>\n",
       "      <td>Kings</td>\n",
       "      <td>New York</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>11234</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606002</th>\n",
       "      <td>34</td>\n",
       "      <td>190</td>\n",
       "      <td>St</td>\n",
       "      <td>Queens</td>\n",
       "      <td>New York</td>\n",
       "      <td>Fresh Meadows</td>\n",
       "      <td>11366</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5239412</th>\n",
       "      <td>3346</td>\n",
       "      <td>Corsa</td>\n",
       "      <td>Ave</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>New York</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>10469</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5248361</th>\n",
       "      <td>1918</td>\n",
       "      <td>Radcliff</td>\n",
       "      <td>Ave</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>New York</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>10462</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5391937</th>\n",
       "      <td>421</td>\n",
       "      <td>118</td>\n",
       "      <td>St</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>10035</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         AddressNumber StreetName PostType CountyName CityTownName  \\\n",
       "5671799           1468         53       St      Kings     New York   \n",
       "4606002             34        190       St     Queens     New York   \n",
       "5239412           3346      Corsa      Ave      Bronx     New York   \n",
       "5248361           1918   Radcliff      Ave      Bronx     New York   \n",
       "5391937            421        118       St   New York     New York   \n",
       "\n",
       "               ZipName  ZipCode State  \n",
       "5671799       Brooklyn    11234    NY  \n",
       "4606002  Fresh Meadows    11366    NY  \n",
       "5239412          Bronx    10469    NY  \n",
       "5248361          Bronx    10462    NY  \n",
       "5391937       New York    10035    NY  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ny_address = pd.read_parquet('Datasets/NYS_clean.parquet.gz', engine='pyarrow')\n",
    "print(f'Dataset shape: {ny_address.shape}')\n",
    "ny_address.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Kings          0.386011\n",
       "Queens         0.234193\n",
       "Richmond       0.166930\n",
       "Bronx          0.136503\n",
       "New York       0.076250\n",
       "Nassau         0.000074\n",
       "Westchester    0.000039\n",
       "Name: CountyName, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the County Distribution: \n",
    "### 62% of the addresses are in Kings (Brooklyn borough) and Quees (Queens borough) county.\n",
    "ny_address['CountyName'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AddressNumber has max length of 5\n",
      "StreetName has max length of 28\n",
      "PostType has max length of 6\n",
      "CountyName has max length of 11\n",
      "CityTownName has max length of 8\n",
      "ZipName has max length of 19\n",
      "ZipCode has max length of 5\n",
      "State has max length of 2\n"
     ]
    }
   ],
   "source": [
    "# Checking the length for each address component. \n",
    "### Max word length is an important parameter for the word embedding that will happen later\n",
    "for col_i in ny_address.columns:\n",
    "    print(f'{col_i} has max length of {ny_address[col_i].astype(str).apply(len).max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3-1\"></a>\n",
    "## 3-1 - Training Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from importlib import reload\n",
    "utils = reload(utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the neural network to output the correct complete address, we need to teach it the relationships between different address components, including street name, city, state and zip code. We do this by generating training data by \"masking\" certain address components. The `context_raw` dataframe contains the \"masked\" addresses, and the `target_raw` dataframe contains the complete addresses. We sample with replacement so that one address can be used for multiple training points in different training epochs.\n",
    "\n",
    "The figure below illustrates the training data generation process. For example, if we mask one complete address three different ways, we will generate three training data points.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"image/mask_generate.PNG\" width=\"800\"> <br>\n",
    "<caption><center><b>Figure 5</b>: Training Data Generation Process </center></caption>\n",
    "</div>\n",
    "\n",
    "One limitation of this method is that not all training data points are equally helpful to the model. This is due to the hierarchical structure of address components. For example, training data point No. 3 will be helpful to the model because we want it to learn to output the most likely zip code for `321 34th St, New York, New York`, which is `10016`. However, training data point No. 1 will not be as helpful, because many addresses can have the zip code `10016`. We expect the model cost function to reduce more with training data point No. 3 than with training data point No. 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_raw,target_raw = utils.create_label_target('Datasets/NYS_clean.parquet.gz')\n",
    "print(f'Context shape: {context_raw.shape}')\n",
    "print(f'Target shape: {target_raw.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked Address: 4015 Church Kings NY 11203\n",
      "Complete Address: 4015 Church Ave Brooklyn Kings NY 11203\n"
     ]
    }
   ],
   "source": [
    "random_numbers = np.random.choice(len(context_raw), 1)[0]\n",
    "print(f'Masked Address: {context_raw[random_numbers]}')\n",
    "print(f'Complete Address: {target_raw[random_numbers]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"Datasets/context_raw.npy\", context_raw)\n",
    "# np.save(\"Datasets/target_raw.npy\", target_raw)\n",
    "\n",
    "context_raw = np.load(\"Datasets/context_raw.npy\")\n",
    "target_raw = np.load(\"Datasets/target_raw.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3-2\"></a>\n",
    "## 3-2 - Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**: Split the dataset into 80% `train_raw` and 20% `val_raw`. Create a `tf.data.Dataset` for these strings. `tf.data.Dataset` is designed to be efficient, both in terms of memory usage and runtime performance. It can automatically parallelize data loading and processing, and it can also be used to cache data in memory or on disk to improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_text as tf_text\n",
    "\n",
    "BUFFER_SIZE = len(context_raw)\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "is_train = np.random.uniform(size=(len(target_raw),)) < 0.8\n",
    "\n",
    "train_raw = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((context_raw[is_train], target_raw[is_train]))\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE))\n",
    "val_raw = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((context_raw[~is_train], target_raw[~is_train]))\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**: We can use the `tf.keras.layers.TextVectorization` to apply preprocessing to the text, and maps text features to integer token sequences. The text standardization is handled by the `utils.tf_lower_and_split_punct`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This parameters defines the saximum size of the vocabulary for this layer\n",
    "max_vocab_size = 5000\n",
    "\n",
    "context_text_processor = tf.keras.layers.TextVectorization(\n",
    "    standardize=utils.tf_lower_and_split_punct,\n",
    "    max_tokens=max_vocab_size,\n",
    "    ragged=True)\n",
    "\n",
    "# The adapt method reads one epoch of the training data, and works a lot like Model.fit. \n",
    "# This method initializes the layer based on the data.\n",
    "context_text_processor.adapt(train_raw.map(lambda context, target: context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_text_processor = tf.keras.layers.TextVectorization(\n",
    "    standardize=utils.tf_lower_and_split_punct,\n",
    "    max_tokens=max_vocab_size,\n",
    "    ragged=True)\n",
    "\n",
    "target_text_processor.adapt(train_raw.map(lambda context, target: target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Address To token: [  2 140 221   5   7   6   4 128   3]\n",
      "Token back to Address\n",
      "[START] 68 96 st brooklyn kings ny 11212 [END]\n"
     ]
    }
   ],
   "source": [
    "# The context_text_processor convert a address into a token sequences\n",
    "# The [START] and [END] represents the Start of String token and End of String token. These tokens will tell the model when to start and stop the prediction.\n",
    "example_text = tf.constant('68 96 St Brooklyn Kings NY 11212')\n",
    "example_tokens = context_text_processor(example_text)\n",
    "print(f'Address To token: {example_tokens}')\n",
    "\n",
    "context_vocab = np.array(context_text_processor.get_vocabulary())\n",
    "tokens = context_vocab[example_tokens.numpy()]\n",
    "print('Token back to Address')\n",
    "print(' '.join(tokens))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3**: Convert the `tf.data.Dataset` to 0-padded tensors of token. The `target_in` and `target_out` is shifted by one step relative to each other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(context, target):\n",
    "    context = context_text_processor(context).to_tensor()\n",
    "    target = target_text_processor(target)\n",
    "    targ_in = target[:,:-1].to_tensor()\n",
    "    targ_out = target[:,1:].to_tensor()\n",
    "    return (context, targ_in), targ_out\n",
    "\n",
    "train_ds = train_raw.map(process_text, tf.data.AUTOTUNE)\n",
    "val_ds = val_raw.map(process_text, tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.Dataset.save(train_ds, \"Datasets/train_ds.tfds\")\n",
    "tf.data.Dataset.save(val_ds, \"Datasets/val_ds.tfds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "# 4 - Encoder, Attention, and Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4-1\"></a>\n",
    "## 4-1 - Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the encoder is to process the context sequence $x^{\\langle T_{x} \\rangle}$ (in our case, the address string) into a sequence of vectors that the decoder can use to predict the next output $y^{\\langle T_{x+1} \\rangle}$.\n",
    "<br>\n",
    "<br>\n",
    "The details of the encoder network is listed below:\n",
    "\n",
    "1. `tf.keras.layers.Embedding`: An embedding layer that convert postive integers (i.e., tokens) into dense vectors\n",
    "\n",
    "2. `tf.keras.layers.Bidirectional`: A bi-directional wrapper for RNNs. Here we use a GRU unit with 256 neurons. The reason we choose a bi-directional GRU is because the hidden state should flow both ways in the encoder. For example, in the exmample address of `4015 Church Ave Brooklyn Kings NY 11203`, the borough component `Brooklyn` should have the hidden state flow from the prior component `4015 Church Ave` and also from the post component `Kings NY 11203`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNITS = 256\n",
    "\n",
    "class GRU_Encoder(tf.keras.layers.Layer):\n",
    "    \"\"\"An encoder model that encodes input sequences into hidden states.\"\"\"\n",
    "\n",
    "    def __init__(self, text_processor, units=UNITS):\n",
    "        \"\"\"Initializes the encoder.\n",
    "\n",
    "        Args:\n",
    "            text_processor: A text processor that can be used to convert text sequences to tensors and vice versa.\n",
    "            units: The dimension of the hidden states.\n",
    "        \"\"\"\n",
    "\n",
    "        super(GRU_Encoder, self).__init__()\n",
    "\n",
    "        self.text_processor = text_processor\n",
    "        self.vocab_size = text_processor.vocabulary_size()\n",
    "        self.units = units\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(self.vocab_size, units, mask_zero=True)\n",
    "\n",
    "        self.rnn = tf.keras.layers.Bidirectional(\n",
    "            merge_mode='sum',\n",
    "            layer=tf.keras.layers.GRU(units, return_sequences=True, recurrent_initializer='glorot_uniform'))\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"Encodes the input sequences.\n",
    "\n",
    "        Args:\n",
    "            x: A tensor of shape `[batch_size, max_sequence_length]`.\n",
    "\n",
    "        Returns:\n",
    "            A tensor of shape `[batch_size, max_sequence_length, units]`.\n",
    "        \"\"\"\n",
    "\n",
    "        # Check the shape of the input tensor.\n",
    "        shape_checker = utils.ShapeChecker()\n",
    "        shape_checker(x, 'batch s')\n",
    "\n",
    "        # Embed the input sequences.\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # Check the shape of the embedded input sequences.\n",
    "        shape_checker(x, 'batch s units')\n",
    "\n",
    "        # Encode the input sequences using the bidirectional LSTM layer.\n",
    "        x = self.rnn(x)\n",
    "\n",
    "        # Check the shape of the encoded input sequences.\n",
    "        shape_checker(x, 'batch s units')\n",
    "\n",
    "        return x\n",
    "\n",
    "    def convert_input(self, texts):\n",
    "        \"\"\"Converts the input texts to a tensor of hidden states.\n",
    "\n",
    "        Args:\n",
    "            texts: A list of strings.\n",
    "\n",
    "        Returns:\n",
    "            A tensor of shape `[batch_size, max_sequence_length, units]`.\n",
    "        \"\"\"\n",
    "\n",
    "        # Convert the input texts to a tensor of text sequences.\n",
    "        texts = tf.convert_to_tensor(texts)\n",
    "\n",
    "        # If the input tensor is a scalar, convert it to a vector.\n",
    "        if len(texts.shape) == 0:\n",
    "            texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
    "\n",
    "        # Convert the text sequences to a tensor of hidden states.\n",
    "        context = self.text_processor(texts).to_tensor()\n",
    "        context = self(context)\n",
    "\n",
    "        return context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4-2\"></a>\n",
    "## 4-2 - Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attention layer allows the decoder to access the information extracted by the encoder. It computes a `context vector` from the entire context sequence, and adds that to the decoder's output.\n",
    "<br>\n",
    "<br>\n",
    "The details of the attention layer is listed below:\n",
    "\n",
    "1. `tf.keras.layers.MultiHeadAttention`: A single head attention layer (num_heads = 1). The `key_dim` is set to 256. This means the attention head for the `query` and `key` will have dimension = 256.\n",
    "\n",
    "    The components of the attention layer is specified here:\n",
    "      * `Batch`: $b$. Number of records in each batch  \n",
    "      * `t`: $t$. Input sequence dimension\n",
    "      * `s`: $s$. Context sequence dimension\n",
    "      * `heads`: $h$. Number of attention heads\n",
    "      * `key_dim`: $key{\\_}dim$. Number of hidden units from the GRU layer\n",
    "\n",
    "    The matrices dimension for each attention component:\n",
    "      * `Query`:  ($b$,$t$,$key{\\_}dim$)\n",
    "      * `Value`:  ($b$,$s$,$key{\\_}dim$)\n",
    "      * `Attention Weights`: ($b$, $t$, $s$)\n",
    "\n",
    "2. `tf.keras.layers.Add`: Concatting the attention output along with the input `X`\n",
    "\n",
    "3. `tf.keras.layers.LayerNormalization`: Normalize the activations of the previous layer for each given example in a batch independently, not across examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"A cross-attention layer that attends to a context sequence to compute a new representation of an input sequence.\n",
    "\n",
    "    Args:\n",
    "        units: The dimension of the hidden states.\n",
    "        kwargs: Additional arguments to pass to the MultiHeadAttention layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        # Create a MultiHeadAttention layer.\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n",
    "\n",
    "        # Create a LayerNormalization layer.\n",
    "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "        # Create an Add layer.\n",
    "        self.add = tf.keras.layers.Add()\n",
    "\n",
    "    def call(self, x, context):\n",
    "        \"\"\"Computes the cross-attention output.\n",
    "\n",
    "        Args:\n",
    "            x: A tensor of shape `[batch_size, input_sequence_length, units]`.\n",
    "            context: A tensor of shape `[batch_size, context_sequence_length, units]`.\n",
    "\n",
    "        Returns:\n",
    "            A tensor of shape `[batch_size, input_sequence_length, units]`.\n",
    "        \"\"\"\n",
    "\n",
    "        # Check the shape of the input tensors.\n",
    "        shape_checker = utils.ShapeChecker()\n",
    "        shape_checker(x, 'batch t units')\n",
    "        shape_checker(context, 'batch s units')\n",
    "\n",
    "        # Compute the attention output and attention scores.\n",
    "        attn_output, attn_scores = self.mha(\n",
    "            query=x,\n",
    "            value=context,\n",
    "            return_attention_scores=True)\n",
    "\n",
    "        # Check the shape of the attention output and attention scores.\n",
    "        shape_checker(x, 'batch t units')\n",
    "        shape_checker(attn_scores, 'batch heads t s')\n",
    "\n",
    "        # Reduce the attention scores to a single head.\n",
    "        attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
    "\n",
    "        # Check the shape of the reduced attention scores.\n",
    "        shape_checker(attn_scores, 'batch t s')\n",
    "\n",
    "        # Store the attention weights for later use.\n",
    "        self.last_attention_weights = attn_scores\n",
    "\n",
    "        # Compute the new representation of the input sequence.\n",
    "        x = self.add([x, attn_output])\n",
    "\n",
    "        # Normalize the new representation of the input sequence.\n",
    "        x = self.layernorm(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def get_shape(self):\n",
    "        \"\"\"Prints the shape of the weights of the MultiHeadAttention layer.\"\"\"\n",
    "        weight_names = ['query', 'keys', 'values', 'proj']\n",
    "        for name, out in zip(weight_names,self.mha.get_weights()):\n",
    "            print(name, out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4-3\"></a>\n",
    "## 4-3 - Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the decoder is to generate predictions for the next token at each location in the target sequence.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "The decoder takes two input:\n",
    "1. `Context`: The context vector from the encoder's output.\n",
    "2. `x`: The target sequence input.\n",
    "\n",
    "The details of the decoder is specified below:\n",
    "1. `tf.keras.layers.Embedding`: An embedding layer that converts token IDs to vectors. This layer is similar between both encoder and decoder.\n",
    "2. `tf.keras.layers.GRU`: A unidirectional GRU layer. During training, the hidden state in the decoder should only flow in one direction because the model predicts the next word at each location.\n",
    "3. `CrossAttention`: The RNN output will be the query for the attention layer.\n",
    "4. `tf.keras.layers.Dense`: A dense layer that produces the logit probability for each output token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_Decoder(tf.keras.layers.Layer):\n",
    "    \"\"\"This class defines a decoder for a sequence-to-sequence model. It uses an LSTM to generate the next token in the sequence, and an attention mechanism to attend to the encoder output.\n",
    "\n",
    "    Args:\n",
    "        text_processor: A TextProcessor object.\n",
    "        units: The number of units in the LSTM layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text_processor, units):\n",
    "        super(GRU_Decoder, self).__init__()\n",
    "        self.text_processor = text_processor\n",
    "        self.vocab_size = text_processor.vocabulary_size()\n",
    "        self.word_to_id = tf.keras.layers.StringLookup(\n",
    "            vocabulary=text_processor.get_vocabulary(),\n",
    "            mask_token='', oov_token='[UNK]')\n",
    "        self.id_to_word = tf.keras.layers.StringLookup(\n",
    "            vocabulary=text_processor.get_vocabulary(),\n",
    "            mask_token='', oov_token='[UNK]',\n",
    "            invert=True)\n",
    "        self.start_token = self.word_to_id('[START]')\n",
    "        self.end_token = self.word_to_id('[END]')\n",
    "\n",
    "        self.units = units\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(self.vocab_size, units, mask_zero=True)\n",
    "        # The embedding layer converts the input tokens into dense vectors.\n",
    "\n",
    "        self.rnn = tf.keras.layers.GRU(units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
    "        # The GRU layer generates the next token in the sequence, based on the previous tokens and the encoder output.\n",
    "\n",
    "        self.attention = CrossAttention(units)\n",
    "        # The attention layer attends to the encoder output, and uses the attended information to generate the next token.\n",
    "\n",
    "        self.output_layer = tf.keras.layers.Dense(self.vocab_size, activation = 'sigmoid')\n",
    "        # The output layer converts the dense vectors generated by the GRU layer into probabilities over the next token.\n",
    "\n",
    "    def call(self,\n",
    "            context, x,\n",
    "            state=None,\n",
    "            return_state=False):  \n",
    "        \"\"\"\n",
    "            Decodes a sequence of tokens based on the context.\n",
    "\n",
    "            Args:\n",
    "              context: A tensor of shape (batch_size, encoder_seq_len, encoder_units).\n",
    "              x: A tensor of shape (batch_size, target_seq_len).\n",
    "              state: A tuple of tensors, (h_state, c_state), of shape (batch_size, units).\n",
    "              return_state: Whether to return the state of the decoder.\n",
    "\n",
    "            Returns:\n",
    "              A tensor of shape (batch_size, target_seq_len, target_vocab_size) containing the logits for the next token in the sequence.\n",
    "            \"\"\"\n",
    "\n",
    "        shape_checker = utils.ShapeChecker()\n",
    "        shape_checker(x, 'batch t')\n",
    "        shape_checker(context, 'batch s units')\n",
    "\n",
    "        # 1. Lookup the embeddings\n",
    "        x = self.embedding(x)\n",
    "        shape_checker(x, 'batch t units')\n",
    "\n",
    "        # 2. Process the target sequence.\n",
    "        x, state = self.rnn(x, initial_state=state)\n",
    "        shape_checker(x, 'batch t units')\n",
    "\n",
    "        # 3. Use the RNN output as the query for the attention over the context.\n",
    "        x = self.attention(x, context)\n",
    "        self.last_attention_weights = self.attention.last_attention_weights\n",
    "        shape_checker(x, 'batch t units')\n",
    "        shape_checker(self.last_attention_weights, 'batch t s')\n",
    "\n",
    "        # Step 4. Generate logit predictions for the next token.\n",
    "        logits = self.output_layer(x)\n",
    "        shape_checker(logits, 'batch t target_vocab_size')\n",
    "\n",
    "        if return_state:\n",
    "            return logits, state\n",
    "        else:\n",
    "            return logits\n",
    "\n",
    "    def get_initial_state(self, context):\n",
    "        batch_size = tf.shape(context)[0]\n",
    "        start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
    "        done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
    "        embedded = self.embedding(start_tokens)\n",
    "        return start_tokens, done, self.rnn.get_initial_state(embedded)[0]\n",
    "\n",
    "    def tokens_to_text(self, tokens):\n",
    "        words = self.id_to_word(tokens)\n",
    "        result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
    "        result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
    "        result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
    "        return result\n",
    "\n",
    "    def get_next_token(self, context, next_token, done, state, random = False):\n",
    "        logits, state = self(\n",
    "            context, next_token,\n",
    "            state = state,\n",
    "            return_state=True) \n",
    "\n",
    "        if not random:\n",
    "            next_token = tf.argmax(logits, axis=-1)\n",
    "        else:\n",
    "            logits = logits[:, -1, :]/1\n",
    "            next_token = tf.random.categorical(logits, num_samples=1)\n",
    "\n",
    "        # If a sequence produces an `end_token`, set it `done`\n",
    "        done = done | (next_token == self.end_token)\n",
    "        # Once a sequence is done it only produces 0-padding.\n",
    "        next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
    "\n",
    "        return next_token, done, state, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4-4\"></a>\n",
    "## 4-4 - Shape Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Deep Learning Specialization course, I learned that it's important to check the matrix shape at every step of the network to prevent weird issues and identify problems early. In this section, we'll pass through one single training datapoint through the network and check the matrix shape for each steps in the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `train_ds`: This is a `tensorflow.python.data.ops.dataset_ops.ParallelMapDataset` dataset with the format of `((context, target_in), target_out)`. `target_out` and `target_in` are target vectors but shifted by one time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context Vector:\n",
      "tf.Tensor([b'[START]' b'202' b'10' b'st' b'kings' b'ny' b'[END]' b'' b''], shape=(9,), dtype=string)\n",
      "\n",
      "\n",
      "Target-In Vector:\n",
      "tf.Tensor([b'[START]' b'202' b'10' b'st' b'brooklyn' b'kings' b'ny' b'11211' b'' b''], shape=(10,), dtype=string)\n",
      "\n",
      "\n",
      "Target-Out Vector:\n",
      "tf.Tensor([b'202' b'10' b'st' b'brooklyn' b'kings' b'ny' b'11211' b'[END]' b'' b''], shape=(10,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# Check one training sample\n",
    "context_layer = tf.keras.layers.StringLookup(vocabulary=context_text_processor.get_vocabulary(),mask_token='', oov_token='[UNK]',invert=True)\n",
    "target_layer = tf.keras.layers.StringLookup(vocabulary=target_text_processor.get_vocabulary(),mask_token='', oov_token='[UNK]',invert=True)\n",
    "\n",
    "for (ex_context_tok, ex_tar_in), ex_tar_out in train_ds.take(1):\n",
    "  print('Context Vector:')\n",
    "  print(context_layer(ex_context_tok[0, :10]))\n",
    "  print('\\n')\n",
    "  print('Target-In Vector:')\n",
    "  print(target_layer(ex_tar_in[0, :10]))\n",
    "  print('\\n')\n",
    "  print('Target-Out Vector:')\n",
    "  print(target_layer(ex_tar_out[0, :10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. `Encoder`: The encoder has an input dimension of ($b$, $s$), and an output dimension of ($b$, $s$, $dim$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context tokens, shape (batch, s): (64, 9)\n",
      "Encoder output, shape (batch, s, units): (64, 9, 256)\n"
     ]
    }
   ],
   "source": [
    "encoder = GRU_Encoder(context_text_processor, UNITS)\n",
    "ex_context = encoder(ex_context_tok)\n",
    "\n",
    "print(f'Context tokens, shape (batch, s): {ex_context_tok.shape}')\n",
    "print(f'Encoder output, shape (batch, s, units): {ex_context.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. `Attention Layer`: The context sequence from the encoder has a dimension of ($b$, $s$, $dim$). The final output of the attention layer has the same dimension as the target sequence ($b$, $t$, $dim$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context sequence, shape (batch, s, units): (64, 9, 256)\n",
      "Target sequence, shape (batch, t, units): (64, 11, 256)\n",
      "Attention result, shape (batch, t, units): (64, 11, 256)\n",
      "Attention weights, shape (batch, t, s):    (64, 11, 9)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = CrossAttention(UNITS)\n",
    "\n",
    "# Attend to the encoded tokens\n",
    "embed = tf.keras.layers.Embedding(target_text_processor.vocabulary_size(), output_dim=UNITS, mask_zero=True)\n",
    "ex_tar_embed = embed(ex_tar_in)\n",
    "\n",
    "result = attention_layer(ex_tar_embed, ex_context)\n",
    "\n",
    "print(f'Context sequence, shape (batch, s, units): {ex_context.shape}')\n",
    "print(f'Target sequence, shape (batch, t, units): {ex_tar_embed.shape}')\n",
    "print(f'Attention result, shape (batch, t, units): {result.shape}')\n",
    "print(f'Attention weights, shape (batch, t, s):    {attention_layer.last_attention_weights.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. `Decoder`: The output of the decoder will have the dimension of ($b$, $t$, $vocab_size$). Given the context and target tokens, for each target token it predicts the next target token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder output shape: (batch, s, units) (64, 9, 256)\n",
      "input target tokens shape: (batch, t) (64, 11)\n",
      "logits shape shape: (batch, target_vocabulary_size) (64, 11, 5000)\n"
     ]
    }
   ],
   "source": [
    "decoder = GRU_Decoder(target_text_processor, UNITS)\n",
    "\n",
    "logits = decoder(ex_context, ex_tar_in)\n",
    "\n",
    "print(f'encoder output shape: (batch, s, units) {ex_context.shape}')\n",
    "print(f'input target tokens shape: (batch, t) {ex_tar_in.shape}')\n",
    "print(f'logits shape shape: (batch, target_vocabulary_size) {logits.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "# 5 - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"addressor_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru__encoder_3 (GRU_Encoder  multiple                 2069504   \n",
      " )                                                               \n",
      "                                                                 \n",
      " gru__decoder_3 (GRU_Decoder  multiple                 3223432   \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,292,936\n",
      "Trainable params: 5,292,936\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from encoder_decoder import Addressor, masked_loss, masked_acc\n",
    "model = Addressor(UNITS, context_text_processor, target_text_processor)\n",
    "\n",
    "logits = model((ex_context_tok, ex_tar_in))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "                  loss=masked_loss, \n",
    "                  metrics=[masked_acc, masked_loss])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gkchen\\Anaconda3\\lib\\site-packages\\keras\\backend.py:5582: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 57s 406ms/step - loss: 2.9795 - masked_acc: 0.4852 - masked_loss: 3.5678 - val_loss: 1.9545 - val_masked_acc: 0.6102 - val_masked_loss: 2.3521\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 36s 361ms/step - loss: 1.6307 - masked_acc: 0.6676 - masked_loss: 1.9697 - val_loss: 1.2413 - val_masked_acc: 0.7531 - val_masked_loss: 1.4736\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 33s 326ms/step - loss: 0.9540 - masked_acc: 0.8104 - masked_loss: 1.1443 - val_loss: 0.7614 - val_masked_acc: 0.8500 - val_masked_loss: 0.9137\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 33s 333ms/step - loss: 0.6352 - masked_acc: 0.8719 - masked_loss: 0.7639 - val_loss: 0.5347 - val_masked_acc: 0.8862 - val_masked_loss: 0.6513\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 32s 324ms/step - loss: 0.4405 - masked_acc: 0.9082 - masked_loss: 0.5293 - val_loss: 0.3759 - val_masked_acc: 0.9191 - val_masked_loss: 0.4481\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 34s 342ms/step - loss: 0.3242 - masked_acc: 0.9272 - masked_loss: 0.3947 - val_loss: 0.2966 - val_masked_acc: 0.9336 - val_masked_loss: 0.3613\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 33s 326ms/step - loss: 0.2500 - masked_acc: 0.9399 - masked_loss: 0.3045 - val_loss: 0.2246 - val_masked_acc: 0.9452 - val_masked_loss: 0.2711\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 33s 332ms/step - loss: 0.2032 - masked_acc: 0.9477 - masked_loss: 0.2447 - val_loss: 0.1704 - val_masked_acc: 0.9536 - val_masked_loss: 0.2090\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 31s 312ms/step - loss: 0.1635 - masked_acc: 0.9546 - masked_loss: 0.1989 - val_loss: 0.1680 - val_masked_acc: 0.9528 - val_masked_loss: 0.1985\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 34s 339ms/step - loss: 0.1504 - masked_acc: 0.9564 - masked_loss: 0.1813 - val_loss: 0.1310 - val_masked_acc: 0.9610 - val_masked_loss: 0.1554\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds.repeat(), \n",
    "    epochs=10,\n",
    "    steps_per_epoch = 100,\n",
    "    validation_data=val_ds,\n",
    "    validation_steps = 20,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(patience=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2b83a3d5640>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+kAAAF4CAYAAAAomLiwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAA9hAAAPYQGoP6dpAACLTUlEQVR4nOzdd3RU1drH8e/MpHeSkBAgQIDQe+9dmiIKIgiCiKhcRUSsXK9dX2woer3YaBZERVFREEGlN2mhdwKhBEICpPeZ948DwUhNckLa77PWrMycOefZe46YnWd2szgcDgciIiIiIiIiUuSsRV0BERERERERETEoSRcREREREREpJpSki4iIiIiIiBQTStJFREREREREigkl6SIiIiIiIiLFhJJ0ERERERERkWJCSbqIiIiIiIhIMaEkXURERERERKSYUJIuIiIiIiIiUkwoSRcREREREREpJoo0SV+xYgX9+vWjYsWKWCwWfvzxx2tes3z5cpo3b46bmxvVq1fno48+KvyKioiIiIiIiNwARZqkJycn07hxYz744IPrOj8yMpK+ffvSsWNHtmzZwr///W/GjRvH999/X8g1FRERERERESl8FofD4SjqSgBYLBZ++OEHbrvttiue8/TTTzN//nx2796dc2zMmDFs3bqVtWvX3oBaioiIiIiIiBQep6KuQF6sXbuWnj175jrWq1cvpk+fTmZmJs7Ozpdck56eTnp6es5ru93OmTNnCAgIwGKxFHqdRURErsXhcJCYmEjFihWxWrVcjBnsdjsnTpzA29tb7b2IiBS5vLT1JSpJP3nyJMHBwbmOBQcHk5WVRWxsLCEhIZdcM2nSJF566aUbVUUREZF8O3r0KJUrVy7qapQKJ06cIDQ0tKirISIiksv1tPUlKkkHLvk2/MJo/St9Sz5x4kQmTJiQ8zo+Pp4qVapw9OhRfHx8Cq+iZcXMm+HkVujzNjQZku8wL/+8k283HuPe9tV4vGdtEysoIlL8JSQkEBoaire3d1FXpdS4cC/V3ouISHGQl7a+RCXpFSpU4OTJk7mOxcTE4OTkREBAwGWvcXV1xdXV9ZLjPj4+arTN0KgvnN0G0Suh0wP5DtOyViW+236GvWey9N9FRMosDcs2z4V7qfZeRESKk+tp60vUxLe2bduyZMmSXMcWL15MixYtLjsfXW6A8PNrBBxcCtmZ+Q7TqLIfADuOJ2C3F4u1DEVERERERG64Ik3Sk5KSiIiIICIiAjC2WIuIiCAqKgowhqqPGDEi5/wxY8Zw5MgRJkyYwO7du5kxYwbTp0/niSeeKIrqC0DFpuARCBmJELUu32HCg7xwc7aSlJ7FodhkEysoIiIiIiJSchRpkr5x40aaNm1K06ZNAZgwYQJNmzbl+eefByA6OjonYQcICwtj4cKFLFu2jCZNmvDKK6/w/vvvM3DgwCKpvwBWK9TsYTzfvzjfYZxsVupX9AVg+/FzJlRMRERERESk5CnSOeldunThatu0z5o165JjnTt3ZvPmzYVYK8mz8Jtg29ewfwn0fCXfYRpW8mXTkbNsOxbP7U21urFIfjkcDrKyssjOzi7qqsh5NpsNJycnzTkXEREpCvZsSE+AtITzP+P/9vz86/T4vz3/x7l3z4MKDW5YdUvUwnFSTNXoBhYrnN4N56LAr0q+wjQONXrStx2LN7N2ImVKRkYG0dHRpKSkFHVV5B88PDwICQnBxcWlqKsiIiJSrDkcDrLtDrIdDrKz7WSnJeJIS8Seeg5HWjyOtAQcafFY0hIg/cLPRKzp8VgyErFmJGBLT8CakYgtMxGnzKQC1edM3Cn8laRLieLhD5VbwdF1Rm96y/vyFaZhJT8Adp6IJyvbjpOtRK1rKFLk7HY7kZGR2Gw2KlasiIuLi3puiwGHw0FGRganT58mMjKS8PBwrFb9fhMRkTyw2yEj6XwPcPzfeoPjc/cE27ONzjMAi+X88/M/LZYrP895/fdrLr3eAWTaLaRn2cnIhrQsOxnZDtKzHaRlOUjPuvDTTtr552mZxvPULDvpWXZSMyEjKxt3RzIejhQ8Hcl4OZLxdKTghfHwIQVvUvC2GD9tFnMWlk5zOJOAJ4kOdxLxIMHhQQIeJDo8cl4n4kGiw/38eR4k4s5rrrXxN6UG10dJupgj/KYCJ+nVAz3xcnUiKT2L/TFJ1A3RljkieZGRkYHdbic0NBQPD4+iro78jbu7O87Ozhw5coSMjAzc3NyKukoiInIjZWeeT6bPXT7BvlLi/fdh2BT9DkgWwOX8w/TA1+hXyHDYjAQaD5LOJ9ZJFg+SLZ4k4UmyxYMUiycpVk+SLZ6k2jxJtXiSYvMi3epFqtUTh80Fm9ViPCyWnOdWqwUnqwWrxYLNCk5WK+5WC14WqGy14uvrZ/Ynviol6WKO8J7w5ysQuRwy08A573+AWq0WGlTyYd2hM2w/Fq8kXSSf1EtbPOm/i4hICeVwQGbqZRLp+Msk2FdIujPNmYZmtzqT4eRNupM3qTYvUiyeJFk8ScCDBLsHadkWMrOzycrOJisrm6xsOw6H/XwO7Mh5WP/xHBxYIOe41WL85G/nXrwGLNhxtlpwsoKLFZysFpysjpxjFx42i3HcyYKR/J7/abVYcLh44nD1weHqC64+ONx8wM0Xi6sPFjcfLO6+WN39sLj7YHXzxcnFA3+blYAyMEpQSbqYo0JD8KoASSfhyGqo2T1fYRpV9mPdoTNsO36OO1uGmlxJERERESnzHA5j6Hhy7PnH6b89/vY6Je78zzNgzzSl6Eybh5FgW71IsRoJdhIenLO7c87hwdksN2Kz3Dmd6cZZuxsJDs+c4dgJeJBegD5sVycrXq5OeJ5/eLnaLj53ucyxnHNtOc8v/PRwtmG1lv5kuagoSRdzWCzGkPctXxhD3vOdpGvxOBERERHJo6z0vyXYsZASe/nE+8LzrLQ8F2HHSrqTN2k2z/M92F4k4UG8w52zdg/OZhsJdmyWW05SbSTZ7iQ4PEnCnWxseS7X29UJLzcnqro54e3mjJerE97nn3u7OeF9/rXX+fe8zifWuRNwm9Z7KkGUpIt5wnueT9IXQ5/X8xWi0fnF43ZHJ5CcnoWnq/6JipQFXbp0oUmTJkyZMqWoqyIiIsWBPRtSz16hl/syP9Pz3sGTZXUj2dmfBJsvZ/Elxu7DySxPjmV4cTLLmzh8iHP4cNbhTQIeJOPGNSdO/42LzYq3u5Fgh7o54e3qjJebkVD7/CPZvnDcSLidzyfdRoKtHuuyRxmQmKd6F7A6wZmDEHcQAmrkOUSovzthgZ5ExiYzb/MxhretZno1RURERKQIZGdB0ilIjIbEk5fp5f77EPM4cNjzFN5ucSLd1Z8kp3IkWHw5gw8xdm9OZHpxNMNIvuMcPjnJdypXX0PJy9WJQC8XQjxdqHU+kfa5TG+2l+vfjp9Ptr1cnXBzznuvuQgoSRczuflAlbZweKUx5D0fSbrFYuGetlV58eddzFxzmGGtq+rbQxEREZHiLj0REqIh8cQ/fkZDwgnjZ9KpPCfema7lSHPxJ8nmxzmrH3EOH05dSLzTPDiS5sFphw+xDh8S8ITUq//d6GKzUt7blVpeLpT3djUeXq4Xn3u7Ut7LjUBvFzxclCpJ0dC/PDFXeM/zSfpiaDMmXyHuaBHK5MX7OHQ6mRX7T9OldpDJlRQpGxwOB6mZ2UVStruzLd97tJ89e5ZHH32Un3/+mfT0dDp37sz7779PeHg4AEeOHGHs2LGsWrWKjIwMqlWrxltvvUXfvn05e/YsY8eOZfHixSQlJVG5cmX+/e9/c++995r58UREyg57ttGznXDiYrJ9yc9oyEi8rnAOqxOZ7kGkuJYn0cmfcxYjwT6Z5c3xTC+i0jw5lOLOyWxvzuJFdtq1e6MtFgjwcqXO3xPvfyTfQeeTbx93p3y3TyI3ipJ0MVd4T1jyHBxeBRnJ4OKZ5xBerk7c2TKU6asimbH6sJJ0kXxKzcym3vO/FUnZu17ule8eiJEjR7J//37mz5+Pj48PTz/9NH379mXXrl04Ozvz8MMPk5GRwYoVK/D09GTXrl14eXkB8Nxzz7Fr1y5+/fVXAgMDOXDgAKmpqWZ+NBGR0iMj+Qq933/rBU88CY7r/MLX1ReHTwhZHhVIcAkk1hLA8exyRKb7sDvZk+0JHuxLdseRcn0LmPm4ORF42Z7u3K/9PVy0KJqUKkrSxVzla4NvFYiPgsiVULt3vsLc07YaM1ZHsmLfaQ7EJFEzyMvkiopIcXQhOV+9ejXt2rUDYPbs2YSGhvLjjz8yaNAgoqKiGDhwIA0bNgSgevXqOddHRUXRtGlTWrRoAUC1atVu+GcQESlydruxuvnlerwTz/eIJ0Rf/2JrFqux1a5PCHiH4PAOIckliBj8OZrlx4F0b3YlebHvrJ0jp1NITMu6ajh/TxdC/T0I9r5y8h3o5ao53VJmKUkXc13Yim3jdGPIez6T9CoBHvSoG8ySXaeYtSaSV29raHJFRUo/d2cbu17uVWRl58fu3btxcnKidevWOccCAgKoXbs2u3fvBmDcuHH861//YvHixfTo0YOBAwfSqFEjAP71r38xcOBANm/eTM+ePbnttttykn0RkVIpLR6O/gVHVhs/z0UZvd/Xu6+3ixd4h5xPwCvm/Mz2CuG0JYAjmT7sT/HgyJk0DselcCQ6maidKaRl/n1ueRZwLlfYEF83qvh7UC3AkyoBxs+qAR5UCfDAx83ZrE8vUiopSRfzhfc8n6QvAYfDSNzzYVT7MJbsOsX3m47zZM86+HroF7pIXlgslhK36I3D4bji8QtzCEePHk2vXr1YsGABixcvZtKkSUyePJlHHnmEPn36cOTIERYsWMDvv/9O9+7defjhh3n77bdv5McQESk8Sachai0cWWMk5qd2XGExNgt4BYFPxb8l3yHnXxs/09yDOJbixJG4FA7HpRAVl8zhqBSizqRw9EwKWfazwNnLVsNmtVDJz52qf0vAq15IxP091AsuUgAl6683KRnCOoLN1RjyfnovBNXJV5g21f2pU8GbPScT+XpDFA92zvtq8SJSstSrV4+srCzWr1+f0wMeFxfHvn37qFu3bs55oaGhjBkzhjFjxjBx4kQ+/fRTHnnkEQDKly/PyJEjGTlyJB07duTJJ59Uki4iJVf8sYsJ+ZE1ELvv0nP8q0PVdlClHQTWMhJyr2CwOZOUnsWRuGSiLiTih5I5HJtC1JnjnIg/wBW+GwXAxcl6vjf8YgJeNcCTqv4eVCrnjrPmgYsUCiXpYj4XT6jWAQ7+YQx5z2eSbrFYGNU+jKe+38bna49wX4cwLQoiUsqFh4fTv39/7r//fj7++GO8vb155plnqFSpEv379wdg/Pjx9OnTh1q1anH27Fn+/PPPnAT++eefp3nz5tSvX5/09HR++eWXXMm9iEix5nBA3MGLCfmRNUanxz8F1TeS8gsP7wrEJKax/tAZDu1N5siZWI7ERXEkLoXYpPSrFunl6mQk4oEXE/ALCXkFHzdthStSBJSkS+EI73kxSW8/Lt9hbm1SkdcX7eH4uVQW7zpF34YhJlZSRIqjmTNn8uijj3LLLbeQkZFBp06dWLhwIc7OxpSX7OxsHn74YY4dO4aPjw+9e/fm3XffBcDFxYWJEydy+PBh3N3d6dixI19//XVRfhwRkSuzZ0PMrr/1lK+F5Jjc51hsULHJxZ7yKm3Aw5/k9CzWR8axalkcqw/sY++pK2+B5u/pktMjXiXAM1fPeICni7YkEylmLI4rTQAspRISEvD19SU+Ph4fH5+irk7pFXcQ/tsMrE7wVCS45f9eT168l//+eYCW1coxd4wWgBK5krS0NCIjIwkLC8PNza2oqyP/cLX/PmqbzKd7KsVSdiaciLjYU350nbHw29/ZXKFyS6ja1kjMK7cCVy8ys+1sO3aOVfvjWH0gls1RZ8myX/wz3mKBeiE+1K/ok5OAX1i0TQu1iRS9vLRL6kmXwhFQA/xrwJmDcGgZ1Ls136HublOVD5cdZMPhs2w/Fk/Dyr7m1VNERESksGSkwPGNF4euH9sAmSm5z3HxgtDW54eut4dKzcDJFYfDwYGYJFZtPM3qA7tZd+gMSem5tzarXM6djuGBtK8ZSLsagfh7utzADycihUVJuhSe8J6w/kNjyHsBkvRgHzduaRTCjxEnmLk6kncGNzGvjiIiIiJmSYuHqPUQdT4pP7750q3Q3P1zzycPbgg240/yUwlprN52mlUHYll9IJZTCbnnk/t5ONO+hpGUd6gZSJUAjxv1yUTkBlKSLoUn/KbzSXrBtmIDuLd9GD9GnODnbSd4pm8dgrw1lFdERESK2PVsh+Zd8W9JeXtj9XWrsRBuYlom6/fG5STl+2OScl3q4mSlVTV/2tcMpGN4IPVCfLSQm0gZoCRdCk/V9uDsAUkn4eR2CGmU71CNQ/1oVsWPzVHnmL0uisduqmViRUVERESuw7mj55Py69gOrWp7qNIWylXL6ajIzLYTEXWOVfuNpHzL0XNk/2NeecNKvjk95c2rltN+4yJlkJJ0KTzObhDWGfb9agx5L0CSDjCqQxibv9rC7PVHeKhrDVyd1GiJiIhIIToXZaytc3j1dWyH1tZYfd3n4k40DoeDfaeScnrK1x+KIzkjO9flVQM8jJ7ymoG0rRGAn4fmlYuUdUrSpXCF33Q+SV8CnZ4oUKhe9SsQ4utGdHwaP2+N5o7mlU2qpIiIiAiQcgYiV0DkciM5P3Mo9/sXtkOr0vZ8T7mxHdrfRcensvqAsQL7qgOxnE7MPa/c39OFdjUC6FDTmFse6q955SKSm5J0KVzhNxk/j/1lNHz/aMjywtlmZXjbqry5aC8zV0cysFkl7espIiIi+ZeZClHrjIT80DKI3gr8bXdiiw0qt4BqHaFa+5zt0P4uIS2TdQcvJuUHTyfnet/N2UrLav45q7DXraB55SJydUrSpXD5VYHydeH0bjj4JzS8o0Dh7mpZhff/2M/OEwn8FXmG1tUDTKqoiIiIlHr2bIiOuJiUR62H7Nw93ZSvC9W7QPXORm+5W+79jDOy7GyJOsvqA7GsPBDLtmPxueaVWy3QsLIfHWoG0L5mIM2qaF65iOSNknQpfOE3GUn6gd8LnKSX83Th9qaVmfNXFDNXH1aSLiIiIlfmcEDcQTi09Pzc8pXGNml/513xfFLexUjMvSv8I4SDPScTc3rK1x86Q2pm7nnlYYGeOcPX21YPwNfDuVA/loiUbkrSpfCF3wRr3jfmpdvtOduO5Ne97asx568oFu86ydEzKZrLJSJUq1aN8ePHM378+Guea7FY+OGHH7jtttsKvV4iUgQST52fU35+XnnCsdzvu/pCWMeLiXlAzctuE5uUnsXXf0Uxa81hjp1NzfVegKdLzgrs7WoGULmc/hYREfMoSZfCF9oGXLwhJRait0Cl5gUKVyvYm47hgazcH8vnaw/z7M31TKqoiIiIlDjpicbK6xeGsMfsyv2+zQVCW59PyrtCSGOwXflP4BPnUpm15jBz1keRmJ4FgLuzjdbV/XN6y2sHe2teuYgUGiXpUvicXKBGF9j9s9GbXsAkHYze9JX7Y/l6w1HG96iFp6v+KYuIiJQJ2ZlwbOPFpPz4RrBn/e0Ei7Hta/UuxlawVdqCy7V7unccj2faykP8si2arPNzzKsHenJfxzAGNquseeUicsMUbNyxyPUK72n83L/YlHBdagURFuhJYloW8zYfu/YFImWRwwEZyUXzcDiuXb/zPv74YypVqoTdbs91/NZbb+Wee+7h4MGD9O/fn+DgYLy8vGjZsiW///67abdp+/btdOvWDXd3dwICAnjggQdISkrKeX/ZsmW0atUKT09P/Pz8aN++PUeOHAFg69atdO3aFW9vb3x8fGjevDkbN240rW4igvH75NROWPs/mD0I3qgGM3vD8tfh6DojQS8XBs1HwqBZ8ORBeHAF3PQy1Ox+1QTdbnfw555T3PXJOm757yp+jDhBlt1B6zB/po1owe8TOjOsdVUl6CJyQ6n7UW6Mmue3Yju+GZJOg1f5AoWzWi2MbFeNF+bvZObqwwxrXVXDzkT+KTMF/q9i0ZT97xPg4nldpw4aNIhx48axdOlSunfvDsDZs2f57bff+Pnnn0lKSqJv3768+uqruLm58dlnn9GvXz/27t1LlSpVClTNlJQUevfuTZs2bdiwYQMxMTGMHj2asWPHMmvWLLKysrjtttu4//77mTNnDhkZGfz111852z8OGzaMpk2b8uGHH2Kz2YiIiMDZWQtGiRTYuaNGL/mFueXJMbnf9wgweskvLPZWrlqewqdlZvPjluNMWxXJgRjjSzmb1cLNDUMY3TGMRpX9zPgUIiL5oiRdbgyfEKjQEE5uh4N/QOMhBQ45sHll3v5tL4dik1m+/zRdaweZUFERudH8/f3p3bs3X331VU6SPnfuXPz9/enevTs2m43GjRvnnP/qq6/yww8/MH/+fMaOHVugsmfPnk1qaiqff/45np7GlwoffPAB/fr144033sDZ2Zn4+HhuueUWatSoAUDdunVzro+KiuLJJ5+kTp06AISHhxeoPiJlVupZiFx5cQj7mYO533f2gKrtLg5hD26Qr4VozyRn8MXaI3yx7jCxSRkAeLk6MaRlKPd2CKOSn3uBP4qISEEpSZcbJ7ynkaTvX2xKku7l6sSdLUOZviqSmasPK0kX+SdnD6NHu6jKzoNhw4bxwAMPMHXqVFxdXZk9ezZDhgzBZrORnJzMSy+9xC+//MKJEyfIysoiNTWVqKioAldz9+7dNG7cOCdBB2jfvj12u529e/fSqVMnRo4cSa9evbjpppvo0aMHd955JyEhIQBMmDCB0aNH88UXX9CjRw8GDRqUk8yLyFVkZ8KR1ReT8hMRwN+myVhsxho2F3rKK7cEJ9d8F3fwdBLTV0Xy/aZjpGcZU2sq+rpxb/swBrcKxcdNI2BEpPhQki43TnhPWDkZDvwB2VlXXVn1eo1sV42ZqyNZse80B2ISqRnkbUJFRUoJi+W6h5wXtX79+mG321mwYAEtW7Zk5cqVvPPOOwA8+eST/Pbbb7z99tvUrFkTd3d37rjjDjIyMgpcrsPhyBm6/k8Xjs+cOZNx48axaNEivvnmG/7zn/+wZMkS2rRpw4svvsjQoUNZsGABv/76Ky+88AJff/01t99+e4HrJlJqndoF34+GmJ25j5evc3EIe7X24OZboGIcDgd/RZ7h05WR/LHnVM5SGQ0r+TK6Yxh9G4bgbNPyTCJS/ChJlxunUgtw84O0c8ZKrFXaFDhkqL8HPeoGs3jXKWauPsxrtzcscEwRufHc3d0ZMGAAs2fP5sCBA9SqVYvmzY2dIFauXMnIkSNzEt+kpCQOHz5sSrn16tXjs88+Izk5Oac3ffXq1VitVmrVqpVzXtOmTWnatCkTJ06kbdu2fPXVV7RpY/wOq1WrFrVq1eKxxx7jrrvuYubMmUrSRS7H4YC/PoHFz0F2uvE3Qe0+F4ew+4SYUkxWtp2FO04ybeUhth2LzznevU4Q93eqTusw/yt+OSciUhzo60O5cWxOxiqrYNoq7wD3tg8DYN7m45xLKXjPmogUjWHDhrFgwQJmzJjB3XffnXO8Zs2azJs3j4iICLZu3crQoUMvWQm+IGW6ublxzz33sGPHDpYuXcojjzzC8OHDCQ4OJjIykokTJ7J27VqOHDnC4sWL2bdvH3Xr1iU1NZWxY8eybNkyjhw5wurVq9mwYUOuOesicl7iKZh9B/z6lJGgh/eEsRvg9o+MKXAmJOiJaZlMW3mIzm8tY9ycLWw7Fo+rk5W7WlXh9wmdmT6yJW2qByhBF5FiTz3pcmOF94Qd3xtJevfnTQnZpro/dUN82B2dwNcbjjKms+aDipRE3bp1w9/fn7179zJ06NCc4++++y6jRo2iXbt2BAYG8vTTT5OQkGBKmR4eHvz22288+uijtGzZEg8PDwYOHJgz1N7Dw4M9e/bw2WefERcXR0hICGPHjuXBBx8kKyuLuLg4RowYwalTpwgMDGTAgAG89NJLptRNpNTY+yv89DCkxIGTG/R8FVqONqbkmODEuVRmrTnMnPVRJKYb+6UHeLowvG1VhrepSoBX/ueyi4gUBYvDkYfNbEuBhIQEfH19iY+Px8fHp6irU/YknYa3wwEHTNgNPuZsD/XtxqM89d02Kvq6seKprjhpjpmUQWlpaURGRhIWFoabm1tRV0f+4Wr/fdQ2mU/3tBjISIHF/4GN043XwQ1g4DQIMme0yY7j8Xy68hALtkWTZTf+nK1e3pPRHaozoFkl7W0uIsVKXtol9aTLjeVVHio1g+Ob4MDv0GyEKWFvbVyRN37dw4n4NBbvOkXfhubMaxMREZF8OBEB8+6H2H3G67ZjjRF0BVihHcBud7BsXwyfrohk7aG4nONtqvtzf8fqdK0dhNWq4ewiUrIpSZcbL7ynkaTvX2xaku7mbGNY6yq8/+cBZqyKVJIuUkbNnj2bBx988LLvVa1alZ07d172PRExid0Oa/8Lf7wC9kzwqmDMO6/RtUBh0zKz+WHLcaatPMTB08kA2KwWbmkUwugO1WlYuWArwYuIFCdK0uXGC78Jlk2Cg8sgKwOcXEwJe3ebqny4/CAbj5xl+7F4NdgiZdCtt95K69atL/ues7P2QRYpVPHH4ccxELnCeF3nFrj1v+Dhn++QcUnpfLkuis/XHiYu2Vgc1svVibtahTKyfRiV/NzNqLmISLGiJF1uvJCm4BEIKbFwdB2EdTIlbJCPGzc3DOHHiBPMXB3JO4ObmBJXREoOb29vvL29i7oaImXPzh/g5/HGNqvOHtDnDWg6PN+Lwx08ncT0VZF8v+kY6VnGbg6V/Ny5t301BrcMxdtNX7qJSOmlJF1uPKvV6E3fOscY8m5Skg4wqkMYP0ac4OdtJ3imTx2CfLR4lpQ9ZWw90BJD/12kVEpPhF+fgYgvjdcVm8KAaRBYM8+hHA4H6yPPMG3lIX7fHZNzvFFlX0Z3rE7fBhW0MKyIlAlK0qVo5CTpS4ytWEzSqLIfzauWY9ORs3y5PooJN9UyLbZIcXdhOHdKSgru7hoCWtykpKQAGnYvpcjRDcbicGcjAQt0fBy6PAO2vP0bz8q2s3DHSaatPMS2Y/E5x3vUDeL+jtVpFeavvc1FpExRki5Fo0Y3sFjh9B44ewTKVTUt9L3tq7HpyFm+Wn+Eh7rU0BYsUmbYbDb8/PyIiTF6oDw8PPSHbTHgcDhISUkhJiYGPz8/bDb9TpISLjsLVr0Dy14HRzb4hsLtH0O19nkKk5iWyTcbjjJz9WGOn0sFwNXJysDmlbmvQxg1ynsVRu1FRIo9JelSNNzLQWhriFoLB5ZAy9Gmhe5dvwIVfd04EZ/Gz1tPMKhFqGmxRYq7ChUqAOQk6lJ8+Pn55fz3ESmxzh6GeQ8aa8oANLgDbp4M7n55CjN7/RFeX7iHxPQsAAI8XRjRthp3t6lCgFfBtmkTESnplKRL0Qm/yUjS95ubpDvZrAxvW403Fu1h5urD3NG8snoTpcywWCyEhIQQFBREZmZmUVdHznN2di7zPehTp07lrbfeIjo6mvr16zNlyhQ6dux4xfNnz57Nm2++yf79+/H19aV37968/fbbBAQE3MBaSw6HA7Z9Cwseh4xEcPUxkvNGd+Y51Oz1R3j2hx0A1CjvyeiO1bm9aSWNfBMROU9JuhSd8J7wx8twaDlkpoGzeYu83dUqlPf+2Meu6AT+ijxD6+r6o07KFpvNVuaTQik+vvnmG8aPH8/UqVNp3749H3/8MX369GHXrl1UqVLlkvNXrVrFiBEjePfdd+nXrx/Hjx9nzJgxjB49mh9++KEIPkEZl3rOSM53fGe8Dm0DAz6GctXyHGre5mP850cjQX+wU3We7l0Hq1VfpIuI/J2WyJSiE9wAvEMgKxWOrDI1tJ+HCwOaVQZgxupIU2OLiEjevPPOO9x3332MHj2aunXrMmXKFEJDQ/nwww8ve/66deuoVq0a48aNIywsjA4dOvDggw+ycePGG1xz4fBq+KiDkaBbbND1WRi5IF8J+q/bo3li7lYcDrinbVWe6aMEXUTkcpSkS9GxWIwh72AMeTfZve2qAbBk1ymOnkkxPb6IiFxbRkYGmzZtomfPnrmO9+zZkzVr1lz2mnbt2nHs2DEWLlyIw+Hg1KlTfPfdd9x8881XLCc9PZ2EhIRcDymA7ExjtNusmyH+KJQLg/sWQ+enwJb3gZhL98Qw7ust2B0wqHllXuhXX1PRRESuoMiT9KlTpxIWFoabmxvNmzdn5cqVVz1/9uzZNG7cGA8PD0JCQrj33nuJi4u7QbUV04Wf/6Nt/2LzQwd70zE8ELsDPl972PT4IiJybbGxsWRnZxMcHJzreHBwMCdPnrzsNe3atWP27NkMHjwYFxcXKlSogJ+fH//973+vWM6kSZPw9fXNeYSGatHQfIs7CNN7wsrJgAOa3g1jVkLlFvkKt+ZALA9+uYnMbAe3NArh9YGN1IMuInIVRZqkX5ij9uyzz7JlyxY6duxInz59iIqKuuz5F+ao3XfffezcuZO5c+eyYcMGRo82b9ExucHCOoPVGc4cMv4oMNmo9mEAfL3hKMnnV5AVEZEb75+9pg6H44o9qbt27WLcuHE8//zzbNq0iUWLFhEZGcmYMWOuGH/ixInEx8fnPI4ePWpq/csEhwM2fWYMbz+xGdz8YNBn0P9/4Oqdr5Cbjpxh9Ocbyciy06NuMO8OboJNCbqIyFUVaZJ+I+aoafhbMefmA1XbGs8LoTe9c63yVA/0JDEti+83HzM9voiIXF1gYCA2m+2SXvOYmJhLetcvmDRpEu3bt+fJJ5+kUaNG9OrVi6lTpzJjxgyio6Mve42rqys+Pj65HpIHKWfgm7vh53GQmQLVOsK/1kD92/IdcsfxeEbO2EBKRjYdwwP5YGhTnG1FPohTRKTYK7LflDdqjpqGv5UAhTjk3Wq1cM/5uekzVx/GbneYXoaIiFyZi4sLzZs3Z8mS3GuPLFmyhHbt2l32mpSUFKzW3H+iXNitwOHQ73HTHVwKH7aDPb8Yo9tuehlGzAffSvkOue9UIsOnrycxPYtW1fz5ZHgLbbEmInKdiixJv1Fz1DT8rQS4kKQfXgUZyaaHv6N5ZbzdnIiMTWb5vtOmxxcRkaubMGEC06ZNY8aMGezevZvHHnuMqKionOHrEydOZMSIETnn9+vXj3nz5vHhhx9y6NAhVq9ezbhx42jVqhUVK1Ysqo9R+mSlw2/Pwhe3QWI0BNaC+/+A9o+CNf9/IkbGJjNs2nrOpmTSuLIv00e2wN1FCbqIyPUq8jFHhT1HTcPfSoDAWuBXBbIzIHKF6eE9XZ0Y3MIYQaHt2EREbrzBgwczZcoUXn75ZZo0acKKFStYuHAhVatWBSA6OjrXejQjR47knXfe4YMPPqBBgwYMGjSI2rVrM2/evKL6CKVPzG74tDus/cB43eI+eGA5hDQuUNhjZ1MY9uk6TiemU6eCN5+NaoW3m7MJFRYRKTssjiIaN5aRkYGHhwdz587l9ttvzzn+6KOPEhERwfLlyy+5Zvjw4aSlpTF37tycY6tWraJjx46cOHGCkJCQa5abkJCAr68v8fHxStiLkwWPw4Zp0GIU3PKu6eGPnkmh81tLsTtgyWOdCA/O3wI4IiKFQW2T+XRPr8DhgL8+hSXPQVYaeARC/w+gdp8Ch45JSGPQx2s5EpdC9fKefPNAW8p7u5pQaRGRki8v7VKR9aRrjprkkjMvfYnxB4TJQv09uKmeMbVi5prDpscXEREp9pJi4Ks74dcnjQS9Zg9jcTgTEvS4pHSGTVvPkbgUQv3dmT26tRJ0EZF8KtLh7pqjJjmqdQSbK8QfhdN7C6WIe89vxzZv8zHOpWQUShkiIiLF0r7fYGpbY5FWmyv0eQuGfQfel19hPy/iUzMZMeMv9sckUcHHja9GtyHE192ESouIlE1ORVn44MGDiYuL4+WXXyY6OpoGDRpcc45aYmIiH3zwAY8//jh+fn5069aNN954o6g+gpjFxQPCOsKB340/IILqmF5E6zB/6ob4sDs6gTl/HeVfXWqYXoaIiEixkpFiDG3fMM14HdwABnwKwfVMCZ+cnsXImX+x80QCgV4uzL6/NaH+HqbEFhEpq4psTnpR0Ry1YmzdR7DoaaNXfeQvhVLE3I1HefK7bVT0dWPFU11x0n6tIlIMqG0yn+4pEL0Nvh8NsedHqLV5GLo/D85upoRPy8zm3pkbWHsoDl93Z75+oA11Q8rovRYRuYYSMSdd5BLhNxk/o9ZCWkKhFNGvcUUCPF04EZ/GbztPFUoZIiIiRcpuh9Xvw6fdjATdqwLcPQ96/59pCXp6VjZjvtzE2kNxeLk68fmoVkrQRURMoiRdio+AGuBfA+xZcGhZoRTh5mxjWOsqgLZjExGRUijhhLHv+ZLnwJ4JdW4xFoer2d20IrKy7Tw6J4Jle0/j5mxlxsiWNA71My2+iEhZpyRdipecVd4XF1oRd7epirPNwqYjZ9l27FyhlSMiInJDHVkDH7aDyOXg7AH93oPBX4JngGlF2O0OnvxuG4t2nsTFZuXTES1oFeZvWnwREVGSLsXNhSHv+5eAPbtQigjyceOWRsZuADNXHy6UMkRERG6oY5tg9iBIPQshTeDBldB8JFgsphXhcDh49scd/LDlOE5WC/8b1oyO4eVNiy8iIgYl6VK8VG0Pbn6QdBI2TC+0Yu5tXw2AX7adICYhrdDKERERKXQnt8OXt0NGEoR1glGLILCmqUU4HA5e+WU3c/6KwmqBdwc34aZ6Bd++TURELqUkXYoXZzfo/pzx/M9XIPFkoRTTqLIfLaqWIzPbwZfrjhRKGSIiIoXu9D74/DZIi4fKrWDIHHA2f4/yd5bsy1nL5fWBjejXuKLpZYiIiEFJuhQ/ze+Fik0hPQF+e7bQirm3fRgAs9dHkZZZOEPrRURECs2ZSPj8VkiJhZDGMGwuuHqZXszUZQf4758HAHi5f33ubBFqehkiInKRknQpfqw2uOVdwAI7viu0ld571Q+moq8bcckZzN96olDKEBERKRTxx40EPTEayteBu38Adz/Ti5m1OpI3Fxn7rD/Tpw4j2lYzvQwREclNSboUTxWbQsvRxvMFj0NWuulFONmsjGhXDTAWkHM4HKaXISIiYrqkGCNBPxcF/tVhxE+mruB+wbcbjvLiz7sAGNc9nDGda5hehoiIXEpJuhRf3f4DnkEQdwDWvF8oRQxpGYqbs5Xd0QmsjzxTKGWIiIiYJuWMMQc97gD4hsKI+eBdwfRifoo4ztPztgEwukMYj/UIN70MERG5PCXpUny5+0Gv14znK9425t6ZzM/DhQHNKgMwY5X58UVEREyTlgBfDoSYneAVbPSg+5k/P3zxzpNM+HYrDgcMa12FZ2+ui8XErdxEROTqlKRL8dZwkLGdTFYa/PoUFMKQ9HvPD3lfsvsUR8+kmB5fRESkwDKS4as74cRmcPc3EvQA84efL993mrFfbSHb7mBA00q80r+BEnQRkRtMSboUbxYL9J0MVmfYvxj2/GJ6EeHB3nQMD8ThgM/WHDY9voiISIFkpsHXwyBqLbj6wvAfIKiu6cWsPxTHg19sJCPbTt+GFXjzjkZYrUrQRURuNCXpUvyVrwXtxxnPf30G0pNML2JUB2M7tm82HCUpPcv0+CIiIvmSnQlzR8KhpeDsCXd/BxWbmF5MxNFzjJq1gbRMO93qBDFlcFOcbPozUUSkKOi3r5QMHZ8AvyqQcAyWv2F6+M7h5ake6EliehbfbzpmenwREZE8s2fDvAdg36/g5AZDv4bQVqYXs+tEAiOmryc5I5t2NQKYOqwZLk76E1FEpKjoN7CUDC4e0Oct4/m6qXBql6nhrVYLI9tXA2DWmsPY7dqOTUREipDdDvPHwc55xpSvO78w1mgx2YGYJIZPX09CWhbNq5bj0xEtcHO2mV6OiIhcPyXpUnLU7g11bgF7lrF3usmLyA1sVhlvNyciY5NZti/G1NgiIiLXzeGARU9DxJdgscId06FWT9OLiYpLYdi0dcQlZ9Cgkg8z722Jp6uT6eWIiEjeKEmXkqX36+DsAVFrYOscU0N7ujoxpKWxlc3M1YdNjS0iInJdHA74/UX46xPAArd9BPX6m17MiXOpDJ22jlMJ6dQK9uLzUa3xcXM2vRwREck7JelSsviFQuenjeeL/wMpZ0wNP6JtNawWWLk/ln2nEk2NLSIick0r3obVU4znt7wDjQebXsTpxHTunraeY2dTqRbgwZf3tcbf08X0ckREJH+UpEvJ0+YhKF8HUuLgj5dNDR3q70HPehUA9aaLiMgNtvZ/sPRV43mv/4MWo0wv4mxyBsOnr+dQbDKV/NyZfX8bgnzcTC9HRETyT0m6lDxOLnDzO8bzTbPg2EZTw997fgG5H7Yc41xKhqmxRURELmvjTPjt38bzrs9C24dNLyIhLZN7Zv7FnpOJBHm7Mnt0ayr5uZtejoiIFIySdCmZqrWHxncBDvjlMcg2b2/zVmH+1AvxIS3Tzpy/jpoWV0RE5LK2fmO0ZQDtx0OnJ00vIiUji/tmbWDbsXj8PV2YPbo11QI9TS9HREQKTkm6lFw3vQJuvnByG2yYZlpYi8XCqA5hAHy+9jCZ2XbTYouIiOSy6yf4cQzggFYPQI8XwWIxtYi0zGwe+HwTGw6fxcfNic9HtSI82NvUMkRExDxK0qXk8ioP3V8wnv/5KiSeNC10v8YhBHq5EB2fxm87zYsrIiKSY99i+O4+cNihyd3Q+w3TE/TMbDtjv9rMqgOxeLjYmDWqFQ0q+ZpahoiImEtJupRszUdCpeaQkXhxLp8JXJ1sDG1dFdACciIiUggiV8C3w8GeCfUHwK3vg9XcP8uy7Q7GfxPB77tjcHWyMv2eljSrUs7UMkRExHxK0qVks9qMReQsVtjxPRxcalrou9tUwdlmYdORs2w9es60uCIiUsYd/Qu+GgJZaVC7Lwz4xGjPTGS3O3j6+20s2BaNs83Cx8Ob07ZGgKlliIhI4VCSLiVfxSbQ8n7j+cInICvdlLBB3m70a1QRgJmrI02JKSIiZdyJCPjyDshMhupd4Y6ZYHM2tQiHw8EL83fy3aZj2KwW/ntXM7rUDjK1DBERKTxK0qV06PYseAVD3AFY/b5pYe9tbywgt2B7NKcS0kyLKyIiZVDMbvjidkiPhyptYchscDZ3j3KHw8Hrv+7hi3VHsFhg8qDG9G5QwdQyRESkcClJl9LBzRd6/Z/xfOXbcMacnu+GlX1pWa0cmdkOvlx3xJSYIiJSBsUdhM9vg9QzULEpDP0WXMzfAu39Pw7w8YpDAPzf7Q25rWkl08sQEZHCpSRdSo8GAyGsszHH79enwOEwJeyF3vSv1keRlpltSkwRESlDzh2Fz/tD0kkIqg93zwM3H9OL+WZDFO/+vg+A526px12tqphehoiIFD4l6VJ6WCxw82SwOsP+xbD7Z1PC9qwXTCU/d+KSM5i/9YQpMUVEpIxIPAmf3wrxRyGgJoz4ETz8TS9md3QCz/+0E4DxPcK5r0OY6WWIiMiNoSRdSpfAcGj/qPF80TOQnlTgkE42KyPaGtuxzVgVicOkHnoRESnlkuOMHvQzh8CvCoyYD17mL+CWlJ7Fw7M3k55lp2vt8ozrFm56GSIicuMoSZfSp9MT4FcVEo7D8tdNCTmkZRXcnW3sOZnIukNnTIkpIiKlWOo5+OI2OL0HvCsaCbqv+fPDHQ4H//lhO4dikwnxdWPynU2wWi2mlyMiIjeOknQpfZzdoe/bxvO1U+HUrgKH9PVwZkAz448rbccmIiJXlZ4EswfByW3gEQgjfgL/whl+/u3Go/wYceL8VmtN8fd0KZRyRETkxlGSLqVTrZ5Q5xZwZMOCCWC3Fzjkve2rAbBk9ymi4lIKHE9EREqhzFSYMwSO/QVufsYc9PK1CqWoPScvzkN/omdtWlQzf667iIjceErSpfTq8wY4e0LUWtj6VYHD1QzyplOt8jgc8NnawwWvn4iIlC5ZGfDtCDi8Ely8jFXcKzQslKKS/zYPvUvt8jzYqXqhlCMiIjeeknQpvXwrQ5enjeeLn4OUgs8lv9Cb/u2GoySlZxU4noiIlBLZWTBvtLG7iJO7sQ965eaFUpTD4eA/P+7g4OlkKvi4MXlQY81DFxEpRZSkS+nW5iEoXxdSz8DvLxY4XOfw8lQv70liehbfbTxa8PqJiEjJZ7fDTw/Drp/A5gJDvoRq7QutuLkbj/HDluPGPPShTQnwci20skRE5MZTki6lm80ZbnnHeL75Mzi6oUDhrFYL97arBsBna49gt2s7NhGRMs3hgIWPw7avwWKDQbOgZo9CK27vyUSen78DgAk31aKl5qGLiJQ6StKl9KvaDpoMM57/8pgxJLEABjSrjLebE5GxySzbF2NCBUVEpERyOGDxf2DjDMACAz6BOjcXWnEpGVk8/NVm0jLtdKpVnn91rlFoZYmISNFRki5lw00vG6vsntoOGz4tUChPVyfualUFgBmrDhe8biIiUjItmwRrPzCe3/o+NLyjUIt77sedHIhJItjHlXfv1Dx0EZHSSkm6lA2egdDjReP5n69BQnSBwo1oWxWrBVYdiGXfqcSC109EREqWVVNg+RvG8z5vQrMRhVrc3I1H+X7zMawWeH+I5qGLiJRmStKl7Gh2D1RqARmJ8Nu/CxSqcjkPetarAMBHyw+aUTsRESkp/voUfn/BeN79BWj9YKEWt+9UIs/9dHEeeuvqAYVanoiIFC0l6VJ2WK3GInIWK+ycBwf/LFC4+8/vSTtv83H+2H3KjBqKiEhxt2U2LHzCeN7xCeg4oVCLS8kw9kNPy7TTMTyQh7rULNTyRESk6ClJl7IlpDG0esB4vuBxyEzLd6jmVctxX4cwAJ76bhsxifmPJSIiJcCO72H+WON5m4eg238Kvcjnf9rJ/pgkgrxdeXdwE81DFxEpA5SkS9nT9VnwqgBnDsHq9woU6sletalTwZu45AyenLsNh0NbsomIlEp7f4V5D4DDbkyf6vV/YCnchPm7Tcf4btP5eeh3NSVQ89BFRMoEJelS9rj5QK/XjOcrJxvJen5DOdt4/66muDpZWb7vNLPWHDanjiIiUnwcXArfjgB7FjS8E255t9AT9P2nEnnuR2Me+mM9atFG89BFRMoMJelSNjUYCNW7QHY6LHzS2Os2n2oFe/PszXUBmPTrHvacTDCpkiIipcfUqVMJCwvDzc2N5s2bs3Llyquen56ezrPPPkvVqlVxdXWlRo0azJgx4wbV9m+i1sPXQyE7A+rcArd9CFZboRaZmpHNw19tJjUzmw41A3moq+ahi4iUJUrSpWyyWKDvZLC5wIHfYff8AoUb3qYqXWuXJyPLzqNzIkjLzDapoiIiJd8333zD+PHjefbZZ9myZQsdO3akT58+REVFXfGaO++8kz/++IPp06ezd+9e5syZQ506dW5grc/zqQjeFaBmD7hjBticCr3IF+bvYN+pJMqfn4du0zx0EZEyxeIoY5NoExIS8PX1JT4+Hh8fn6KujhS1P1+DFW+Cd0UY+xe4euc7VGxSOr2nrCA2KYN721fjhX71TayoiJRmpb1tat26Nc2aNePDDz/MOVa3bl1uu+02Jk2adMn5ixYtYsiQIRw6dAh/f/98lWnqPU2KMdoHZ/eCxbkO8zYfY8K3W7Fa4MvRrWlXI7DQyxQRkcKXl3apyHvSS+zwNykdOk6ActUg8QQse71AoQK9XHlrUGMAZq4+zLK9MSZUUESkZMvIyGDTpk307Nkz1/GePXuyZs2ay14zf/58WrRowZtvvkmlSpWoVasWTzzxBKmpqVcsJz09nYSEhFwP03gF3ZAE/UBMIs/+YMxDf7R7LSXoIiJlVJEm6SV6+JuUDs7u0Pdt4/m6D+HkjgKF61o7iJHtqgHwxNxtxCalF7CCIiIlW2xsLNnZ2QQHB+c6HhwczMmTJy97zaFDh1i1ahU7duzghx9+YMqUKXz33Xc8/PDDVyxn0qRJ+Pr65jxCQ0NN/RyFLTUjm4dnbyE1M5t2NQIY203z0EVEyqoiTdLfeecd7rvvPkaPHk3dunWZMmUKoaGhuYbD/d2iRYtYvnw5CxcupEePHlSrVo1WrVrRrl27G1xzKVXCb4K6/cCRDQsmgN1eoHDP9KlDrWAvYpPSefo7bcsmIgJg+cdq6A6H45JjF9jtdiwWC7Nnz6ZVq1b07duXd955h1mzZl2xN33ixInEx8fnPI4ePWr6ZyhML/28k72nEgn0cmXKEM1DFxEpy4osSS8Vw9+k9Oj9Ojh7wtH1EDG7QKHcnG28N6QpLk5W/tgTw5frrzwyRESktAsMDMRms13Sax4TE3NJ7/oFISEhVKpUCV9f35xjdevWxeFwcOzYscte4+rqio+PT65HSfHDlmN8veEoFgu8P6QJQd5uRV0lEREpQkWWpGv4mxQrvpWh60Tj+ZLnIeVMgcLVDfHhmd7GNIxXf9nFgZjEgtZQRKREcnFxoXnz5ixZsiTX8SVLllxxJFz79u05ceIESUlJOcf27duH1WqlcuXKhVrfG+1ATFLOPPRx3cJpV1Pz0EVEyroiXzhOw9+k2Gg9BoLqQeoZ+P2FAocb2a4anWqVJz3LziNzIkjP0rZsIlI2TZgwgWnTpjFjxgx2797NY489RlRUFGPGjAGMtnrEiBE55w8dOpSAgADuvfdedu3axYoVK3jyyScZNWoU7u6Fv4DbjZKWmc3YrzaTkpFN2+oBjOseXtRVEhGRYqDIknQNf5Nix+YMN79jPN/8ORz9q0DhrFYLb9/RCH9PF3ZHJ/D2b3tNqKSISMkzePBgpkyZwssvv0yTJk1YsWIFCxcupGrVqgBER0fnWjTWy8uLJUuWcO7cOVq0aMGwYcPo168f77//flF9hELx0s872XMykUAvF967S/PQRUTE4JSfi5KTk3n99df5448/iImJwf6PhbYOHTp0zRh/H/52++235xxfsmQJ/fv3v+w17du3Z+7cuSQlJeHl5QWU3uFvUkSqtoUmd0PEl/DLBHhgGdjy9b8JAEE+brwxsBH3f76RT1dG0rlWEB3CNZRRREoGM9r7Cx566CEeeuihy743a9asS47VqVPnkiHypclPEceZ85cxD33K4Kaahy4iIjnylX2MHj2a5cuXM3z4cEJCQq44PP1aJkyYwPDhw2nRogVt27blk08+uWT42/Hjx/n8888BY/jbK6+8wr333stLL71EbGxsqRz+JkXsppdh7wI4tR3++gTaXv6PyusOVy+Yu9tU4ct1UUz4NoLfxneinKeLSZUVESk8ZrX3ktuh00n8e952AB7pWlNf3oqISC75StJ//fVXFixYQPv27QtU+ODBg4mLi+Pll18mOjqaBg0aXNfwt0ceeYQWLVoQEBDAnXfeyauvvlqgeojk4hkAPV6Enx+Fpa9B/dvAp2KBQj7btx5rD8Zx8HQyT3+/jY+HN9cfuyJS7JnV3stFaZnZPPzVFpIzsmlT3Z9He9Qq6iqJiEgxY3HkYxPnsLAwFi5cSN26dQujToUqISEBX19f4uPjNT9drsxuhxk94dgGqH87DJpV4JA7jsdz+9TVZGY7mDSgIXe1qlLweopIqVBc2ya19+b79w/b+Wp9FIFeLiwc15EgHw1zFxEpC/LSLuVr4bhXXnmF559/npSUlHxVUKTYs1qNReQsVtj5Axz4o8AhG1Ty5cletQF4+eddHDyddI0rRESKltp7c83feoKv1kdhscC7g5soQRcRkcvKV09606ZNOXjwIA6Hg2rVquHs7Jzr/c2bN5tWQbMV12/WpZhaNBHWTQX/6vCvteBcsD+o7HYHw2esZ/WBOBpW8uX7f7XDxanId0IUkSJWXNsmtffmiYxN5pb3V5Kckc0j3WryeM/aRV0lERG5gfLSLuVrTvptt92Wn8tESp4uE42e9DOHYPUU6PJMgcJZrRYmD2pC7/dWsP14PO8s2cczfeqYU1cREZOpvTdHWmY2D83eTHJGNq3C/HlU+6GLiMhV5KsnvSQrbt+sSwmwYx58dy/YXOGhtRBQo8AhF+04yZgvN2GxwOzRrWlXQyv7ipRlapvMV5zu6X9+3M6X66II8HRh4aMdCdYwdxGRMqfQ56QDnDt3jmnTpjFx4kTOnDkDGMPejh8/nt+QIsVT/duhelfIToeFT4IJ32v1blCBIS1DcThgwjdbOZeSYUJFRUTMp/a+YH7eeoIv1xk71bwzuIkSdBERuaZ8Jenbtm2jVq1avPHGG7z99tucO3cOgB9++IGJEyeaWT+RomexwM2TweYCB/+AXT+aEvb5fvWoHujJyYQ0/v3DdsrYoBYRKQHU3hfM4dhkJp7fD/3hrjXoXKt8EddIRERKgnwl6RMmTGDkyJHs378fN7eL3wj36dOHFStWmFY5kWIjoAZ0eMx4vmgipCcWOKSHixNThjTByWph4faTzN10rMAxRUTMpPY+/4z90DeTlJ5Fq2r+PKb90EVE5DrlK0nfsGEDDz744CXHK1WqxMmTJwtcKZFiqcNjUC4MEqNh6SRTQjaq7MeEnsYfbi/O38nh2GRT4oqImEHtff69tmA3O08k4O/pwvt3NcXJpp08RETk+uSrxXBzcyMhIeGS43v37qV8eQ3lklLK2R36vm08X/8RnNxuStgHO9WgdZg/KRnZPPpNBJnZdlPiiogUlNr7/FmwLZov1h0B4J07G1PBV/PQRUTk+uUrSe/fvz8vv/wymZmZAFgsFqKionjmmWcYOHCgqRUUKVbCe0C9/uDIhl8mgL3gCbXNauHdwU3wcXNi69FzvP/HfhMqKiJScGrv8+5IXDJPf78NgH91qUGX2kFFXCMRESlp8pWkv/3225w+fZqgoCBSU1Pp3LkzNWvWxNvbm9dee83sOooUL70mgYsXHPsLIr40JWRFP3cmDWgEwP+WHuCvyDOmxBURKQi193mTnnVxHnqLquV4/CbNQxcRkbwr0D7pf/75J5s3b8Zut9OsWTN69OiBw+HAYrGYWUdTFad9U6UEW/MBLH4W3MvB2E3gGWBK2CfmbuW7Tceo5OfOwkc74uvubEpcESneinvbpPb++rzw0w4+W3uEch7OLHy0IyG+7jekXBERKf4KfZ/0SZOMRbO6devGE088wVNPPUWPHj3Izs5m6NCh+QkpUrK0fhCC6kPqWVj4hCl7pwO8eGt9qvh7cPxcKv/5cYe2ZRORIqX2/vot3B7NZ2svzENvogRdRETyLV9J+pQpU/jkk09yHcvOzmbIkCFERESYUS+R4s3mDP2mgMUGO+fBMnNWe/dydeK9IU2wWS38vPUEP0YcNyWuiEh+qL2/PlFxKTz9nTEPfUznGnSto3noIiKSf/lK0hcuXMjTTz/Nt99+C0BmZiaDBg1i586dLF261NQKihRboa3glneN58vfgM1fmBK2aZVyjO8eDsBzP+4kKi7FlLgiInml9v7aLsxDT0zPonnVcjzeU/PQRUSkYJzyc1Hz5s354Ycf6N+/P66urkyfPp2DBw+ydOlSgoODza6jSPHV/B44FwUr34afHwWfilCze4HDPtS1Jiv2n2bD4bOM/2YL3z7YVnvsisgNp/b+2iYt3MP24/H4eTjz37ua4qzf1SIiUkD5bkm6dOnCF198wR133MHhw4dZvny5Gmwpm7r9BxoNNrZl+/YeU/ZPt1ktvHNnE7xdndgcdY4Plh4woaIiInmn9v7KFu2IZtaaw4CxH3pFP81DFxGRgrvunvQBAwZc9nj58uXx8/PjgQceyDk2b968gtdMpKSwWODWDyDhBBxeCbPvhNG/g2+lAoUN9ffg1dsb8OjXEbz/x346hgfSvKq/SZUWEbk8tffXJyouhSfPz0N/sFN1utXRFxciImKO607SfX19L3u8V69eplVGpMRycoHBX8KMXnB6D8weBKN+BbfL/39zvfo3qcSyvaf5Yctxxn8TwcJxHfF207ZsIlJ41N5fW0aWnUfmbCYxLYtmVfx4olftoq6SiIiUIgXaJ70kKu570UoJdy4KpvWApFNQvSsMm2usBF8ACWmZ9H1vJcfOpjKgaSXeGdzEnLqKSLGhtsl8hXlPX/p5JzNXH8bX3dgPvZKGuYuIyDUU+j7pF5w+fZpVq1axevVqTp8+XZBQIqWDXxUY+i04e8KhpfDz+ALvoe7j5syUwU2wWmDeluP8pG3ZROQGU3t/0W87TzJz9WEAJg9qrARdRERMl68kPTk5mVGjRhESEkKnTp3o2LEjFStW5L777iMlRdtFSRlXsQkMmgUWK0R8CcvfLHDIFtX8GdvN2JbtPz/u4NhZ/X8mIoVP7X1uR8+k8OTcrQDc3zGMHvU0D11ERMyXryR9woQJLF++nJ9//plz585x7tw5fvrpJ5YvX87jjz9udh1FSp5aPeHmycbzZf8HEV8VOOS4bjVpWsWPxLQsJnyzlWx7mZqpIiJFQO39RRlZdsbO2UJCWhZNq/jxVO86RV0lEREppfI1Jz0wMJDvvvuOLl265Dq+dOlS7rzzzmI9FE7z/uSG+v1FWPUuWJ3g7u+hepcChYuKS6HPeytIzsjmiZ61cnrXRaRkK65tk9r7i175ZRfTV0Xi6+7MgnEdqFzOw4RaiohIWVHoc9JTUlIuu0dqUFBQmRz+JnJF3Z6HBgPBngXfDIdTOwsUrkqABy/3bwDAu7/vJ+LoORMqKSJyeWrvDYt3nmT6qkgA3h7UWAm6iIgUqnwl6W3btuWFF14gLS0t51hqaiovvfQSbdu2Na1yIiWe1Qq3fQhV20N6grE1W8KJAoUc0KwStzQKIdvu4NGvt5CcnmVSZUVEclN7b8xDf+L8PPT7OoRxk+ahi4hIIbvufdL/bsqUKfTp04fKlSvTuHFjLBYLERERuLm58dtvv5ldR5GSzcnV2EN9ek+I2w+z7zT2UHf1zlc4i8XCa7c3ZEvUOY7EpfDi/J28NaixyZUWEVF7DxCblI6rs43G5b14WvPQRUTkBsj3Pumpqal8+eWX7NmzB4fDQb169Rg2bBju7sV7K5LiOu9PyoCzh4091JNPQ43uMPSbAu2hvv5QHEM+XYfDAf8b2oybG4WYV1cRuaGKc9uk9h5OJ6aTmW2norZbExGRfMpLu5SvJH3FihW0a9cOJ6fcHfFZWVmsWbOGTp065TXkDVOc/xCSMuD4Zph1M2SmQLMR0O99sFjyHe6t3/bwv6UH8XFzYtH4TvoDUqSEKq5tk9p7ERERcxT6wnFdu3blzJkzlxyPj4+na9eu+QkpUjZUagZ3zDD2UN/8OaycXKBw43vUonFlXxLSspjwbYS2ZRMRU6m9FxERufHylaQ7HA4sl+n9i4uLw9PTs8CVEinVaveBPm8az/98BbZ9m+9QzjYrU4Y0xcPFxrpDZ/hkxSGTKikiovZeRESkKORp4bgBAwYAxsJVI0eOxNXVNee97Oxstm3bRrt27cytoUhp1Op+OHcE1vwXfnwIvCtAWP6GjYYFevJiv/o89f02Ji/eS4eagTSs7GtyhUWkLFF7LyIiUnTylKT7+hp/+DscDry9vXMtGuPi4kKbNm24//77za2hSGnV42U4dxR2/Qhf3w33/QZBdfMValCLyizdG8OvO07y6Ndb+GVcBzxc8rV5g4iI2nsREZEilKe/4v/73//i5eVFtWrVeOKJJzTUTaQgrFa4/WNIPAlH1xl7qI/+3ehVzyOLxcKkAca2bIdik3nll91MGtCwECotImWB2nsREZGik6c56YGBgfTp04egoCDi4+MLq04iZYezG9w1B/xrQPxR+OpOSE/KVyg/DxfeGdwYiwXm/BXFoh0nTa6siJQVau9FRESKTp6S9L1799K3b1++//57wsLCaNmyJa+88grbtm0rrPqJlH4e/nD3d+ARCNFb4bt7ITsrX6Ha1QjkgU7VAXhm3jZOJaSZWVMRKSPU3ouIiBSdfO2TDsb2KwsXLuSnn35i0aJFlCtXjltvvZX+/fvTuXNnbDab2XU1hfZNlWLr2EaYdQtkpUKLUXDzO/naQz0jy86AD1ez43gCHWoG8vmoVlit+d+LXUQKX3Fum9Tei4iIFFyh75MOxqIyd911F19//TWxsbF8/PHH2O127r33XsqXL8/s2bPzG1qkbKrcAgZOAyywcQasnpKvMC5OVqYMboqbs5VVB2KZsTrS1GqKSNmi9l5EROTGyndP+tVs2bKFrKwsWrZsaXboAtM361LsrfsIFj1tPB84HRreka8wX62P4t8/bMfFZuWHh9tRv6K2ZRMprkpq26T2XkRE5PoUWk/6m2++SWpqas7rFStWkJ6envM6MTGRhx56iKZNmxbLBlukRGgzBto8bDz/8V9weHW+wtzVKpSb6gWTkW3n0a8jSM3INrGSIlKaqb0XEREpOnnqSbfZbERHRxMUFASAj48PERERVK9uLFR16tQpKlasSHZ28U0G9M26lAh2O8wdAbt/Bjc/uG8JlK+V5zBnkjPoNWUFpxPTGd6mKq/c1sD8uopIgRW3tkntvYiIiLkKrSf9n/l8IYyUFxEw9lAf8ClUbglp52D2QEiKyXMYf08XJg9qDMAX644we/0RkysqIqWR2nsREZGik++F40SkkDm7w11fQ7kwOBdl7KGekZznMJ1qlefB89uyPfvDDl75ZRfZdv3BLSIiIiJSHClJFynOPAPh7u/B3R9ObIHv7gN73oeXPtOnDo/1MIbLT18Vyf2fbyQxLdPs2oqIiIiISAE55fWCadOm4eXlBUBWVhazZs0iMDAQMBaSERGTBdQwetQ/6wf7foVfn4a+b+VpD3WLxcKjPcKpEeTJ499u5c89Mdzx4Vqm3dOCUH+PQqy8iJRUau9FRESKRp4WjqtWrRqW60gMIiOL777MWkhGSqxdP8G39wAO6PkqtHskX2Eijp7j/s83cjoxnQBPFz4e3pwW1fzNrauI5Elxa5vU3ouIiJgrL+1SoeyTXpyp0ZYSbc0HsPhZ4/mgWVD/9nyFiY5PZfRnG9l5IgEXm5XXBzZkQLPK5tVTRPJEbZP5dE9FRKQ4KbTV3f/880/q1atHQkLCJe/Fx8dTv359Vq5cmbfaisj1a/swtHrQeD7vQYhal68wIb7uzB3Tll71jX3UJ3y7lTcX7cGuBeVEBLX3IiIiRSlPSfqUKVO4//77L5v5+/r68uCDD/LOO++YVjkR+QeLBXpPgto3Q3Y6zBkCsQfyFcrDxYkPhzXnoS41AJi67CD/mr2JlIwsM2ssIiWQ2nsREZGik6ckfevWrfTu3fuK7/fs2ZNNmzYVuFIichVWGwycBpWaQ+rZ83uon85fKKuFp3rXYfKgxrjYrPy28xSDPlpLdHyqyZUWkZKkMNr7qVOnEhYWhpubG82bN7/unvjVq1fj5OREkyZN8lSeiIhISZWnJP3UqVM4Oztf8X0nJydOn85fsiAieeDiAXd9A35V4exho0c9IyXf4QY2r8xX97cmwNOFnScS6P/BarYePWdadUWkZDG7vf/mm28YP348zz77LFu2bKFjx4706dOHqKioq14XHx/PiBEj6N69+3WXJSIiUtLlKUmvVKkS27dvv+L727ZtIyQkJE8V0DfrIvnkVf78Hurl4PhGmHd/vvZQv6BFNX9+fLg9tYK9iElM586P1/LLthMmVlhESgqz2/t33nmH++67j9GjR1O3bl2mTJlCaGgoH3744VWve/DBBxk6dCht27a97rJERERKujwl6X379uX5558nLS3tkvdSU1N54YUXuOWWW647nr5ZFymgwHAYMgdsrrDnF/jt2QKFC/X34Pt/taNr7fKkZ9kZ+9UW3vt9P2VsEwiRMs/M9j4jI4NNmzbRs2fPXMd79uzJmjVrrnjdzJkzOXjwIC+88MJ1lZOenk5CQkKuh4iISEmUpyT9P//5D2fOnKFWrVq8+eab/PTTT8yfP5833niD2rVrc+bMGZ599vqTBH2zLmKCqm3h9vP/z6z/ENZOLVA4bzdnpt3Tkvs6hAHw7u/7ePTrCNIy899LLyIli5ntfWxsLNnZ2QQHB+c6HhwczMmTJy97zf79+3nmmWeYPXs2Tk5O11XOpEmT8PX1zXmEhoZe13UiIiLFzfW1fOcFBwezZs0a/vWvfzFx4sSc3jWLxUKvXr2YOnXqJY3wlVz4Zv2ZZ57Jdfx6v1n/8ssvefXVV69ZTnp6Ounp6Tmv9c26lEoNBkL8MVjyPPz2b/CtDPVuzXc4m9XCc7fUo2aQF8/9uIP5W08QdSaFT0Y0J8jbzcSKi0hxZGZ7f4HFYsn12uFwXHIMIDs7m6FDh/LSSy9Rq1at644/ceJEJkyYkPM6ISFBibqIiJRIeUrSAapWrcrChQs5e/YsBw4cwOFwEB4eTrly5fIUpyDfrK9cuTJP36y/9NJLeaqbSInUbhycPQIbpxvz070rQGirAoW8q1UVqgZ48K8vNxNx9By3fbCaafe0pF7FS7dlEpHSxaz2PjAwEJvNdknbHhMTc9lEPzExkY0bN7JlyxbGjh0LgN1ux+Fw4OTkxOLFi+nWrdsl17m6uuLq6pqnuomIiBRHeRru/nflypWjZcuWtGrVKs8N9t/diG/W4+Pjcx5Hjx7Nd11FijWLBfq8CbV6Q1aaseJ73MECh21XI5AfH25P9UBPTsSnccdHa1iy65QJFRaRkqCg7b2LiwvNmzdnyZIluY4vWbKEdu3aXXK+j48P27dvJyIiIucxZswYateuTUREBK1bt873ZxERESkJ8tyTbhZ9sy5SCGxOcMcMmNkXoiNg9h1w3+/gGVCgsGGBnvzwUHse/mozqw7E8sAXG3m6dx0e7FT9sl+qiYj83YQJExg+fDgtWrSgbdu2fPLJJ0RFRTFmzBjA+EL9+PHjfP7551itVho0aJDr+qCgINzc3C45LiIiUhrluye9oPTNukghcfGEod+CbxU4c8joUc9MLXBYXw9nZt7bkrvbVMHhgNd/3cOT320jPUsLyonI1Q0ePJgpU6bw8ssv06RJE1asWMHChQupWrUqANHR0dfc2UVERKSssDiKcG+lb775huHDh/PRRx/lfLP+6aefsnPnTqpWrZrrm/XLefHFF/nxxx+JiIi47jITEhLw9fUlPj4eHx/Nq5VS7PRemH4TpMVD3Vth0GdgLfj3cg6Hg8/WHOblX3Zhd0Crav58NLw5/p4uJlRapGxS22Q+3VMRESlO8tIuFVlPOuibdZFCVb42DPkKbC6wez4sec6UsBaLhZHtw5gxsiXerk78dfgM/f+3iv2nEk2JLyIiIiJSlhVpT3pR0DfrUuZsmwvzRhvPGwyEHi+BnznbEu0/lch9n20k6kwK3q5O/HdoU7rUDjIltkhZorbJfLqnIiJSnJSYnnQRuQEaDYKerwIW2PE9fNAC/nwNMpILHDo82JsfH25Pq2r+JKZnMWrWBmaujqSMffcnIiIiImIaJekiZUG7R+DB5VC1vbE924o34b/NYevXYLcXKLS/pwtfjG7FoOaVsTvgpZ938Z8fd5CZXbC4IiIiIiJlkZJ0kbIipDGMXAB3fg5+VSAxGn54EKb3gKN/FSi0q5ONN+9oxMQ+dbBYYPb6KEbO/Iv4lEyTKi8iIiIiUjYoSRcpSywWqNcfHt4A3V8AFy84vslYBf770RB/rAChLTzYuQafDG+Bh4uN1QfiuH3qaiJjCz6sXkRERESkrFCSLlIWObtBxwnwyCZoejdgge1z4b8tYOkkyEjJd+ib6gXz3Zh2VPR141BsMrf9bzVrDsSaV3cRERERkVJMSbpIWeZdAfr/Dx5YClXaQlYqLH/dWFxu27f5nq9er6IPP45tT9MqfsSnZjJixl98tV7bKYqIiIiIXIuSdBGBik3h3l9h0CzwrQIJx2He/cYw+GMb8xUyyNuNOfe34dbGFcmyO/j3D9t56eedZNu18ruIiIiIyJUoSRcRg8UC9W+HsRug23Pg7AnHN8K07jDvAYg/nueQbs423hvShAk31QJg5urD3PfZBhLTtKCciIiIiMjlKEkXkdyc3aDTEzBuMzQZZhzb9o0xBH7ZG3mer26xWBjXPZz/DW2Gm7OVZXtPM/DDNRw9k/957yIiIiIipZWSdBG5PO8KcNtUuH8phLaBzBRY9n/wQUvY/h048jZs/eZGIXz7YFuCvF3ZdyqJ/v9bzYbDZwqp8iIiIiIiJZOSdBG5ukrNYNQiuGMm+IZCwjH4/j6Y3hOObcpTqEaV/fhpbHvqV/ThTHIGwz5dz/eb8r/tm4iIiIhIaaMkXUSuzWKBBgOM+epd/wPOHnDsL5jWDeY9CAknrjtUiK87c8e0pXf9CmRk23l87lbeWLQHuxaUExERERFRki4ieeDsDp2fhEc2Q+O7jGPbvob/Noflb0Jm6nWF8XBxYuqwZjzctQYAHy47yJgvN5GcnlVYNRcRERERKRGUpItI3vmEwO0fwf1/QmhrY7760teM+eo7vr+u+epWq4Une9Xh3cGNcbFZWbzrFIM+WsuJc9eX6IuIiIiIlEZK0kUk/yo1h1G/wcDp4FMZ4o/Cd6NgRi84fn3z1W9vWpk5D7QmwNOFXdEJ9P/faiKOnivceouIiIiIFFNK0kWkYCwWaHjH+fnqzxrz1Y+uh0+7wQ//goToa4ZoXtWfHx9uT+1gb04npnPHh2t4/qcdxCSm3YAPICIiIiJSfChJFxFzuHhA56dg7EZoNMQ4tvUrY776ireuOV891N+D7x9qR+/6FciyO/h87RG6vLWMyYv3kpiWeQM+gIiIiIhI0VOSLiLm8q0EAz6G0X9C5VaQmQx/vgoftIId8646X93L1YmPhjfnq/tb0zjUj5SMbP775wE6v7WM6asiSc/KvoEfRERERETkxrM4HNexwlMpkpCQgK+vL/Hx8fj4+BR1dURKN4cDtn8Hv78ACceNY1XaQu9JULHpNS51sGjHSd76bS+HYpMBqOTnzoSbanFb00rYrJbCrr3IDaO2yXy6pyIiUpzkpV1Ski4ihS8jBda8D6umQFYqYIEmw6D7c+Bd4aqXZmXbmbvpGFN+38ephHQAagd781Tv2nSrE4TFomRdSj61TebTPRURkeJESfpVqNEWKULxx+H3F2H7t8ZrFy/oOAHaPAzOble9NDUjm1lrDvPhsgMkpBn7qbesVo5n+tSheVX/Qq64SOFS22Q+3VMRESlOlKRfhRptkWLg6AZY9Awc32i89qsCN70C9fobq8VfRXxKJlOXH2DW6sOkZ9kB6FE3mKd616ZWsHdh11ykUKhtMp/uqYiIFCdK0q9CjbZIMWG3w47vYMkLkHjCOFa1vTFfPaTxNS+Pjk/lvd/38+3Go9gdYLXAgGaVeeymWlTycy/kyouYS22T+XRPRUSkOFGSfhVqtEWKmYxkWP0+rH4v93z1Ls+AX+g1Lz8Qk8Tbv+1l0c6TALg4WRnRpioPd61JOU+XQq68iDnUNplP91RERIoTJelXoUZbpJiKP3Z+vvpc47XNBVqMgo6Pg1fQNS/fEnWWNxbtYd2hMwB4uzrxYOfqjOoQhoeLUyFWXKTg1DaZT/dURESKEyXpV6FGW6SYO7oB/ngJDq80Xjt7QOsHod048Lj6AnEOh4Pl+07zxqK97I5OAKC8tyvjuoczpGUozjZrYddeJF/UNplP91RERIoTJelXoUZbpARwOODQMvjzFTi+yTjm6gPtHoE2/wLXqy8QZ7c7+HnbCd5evJejZ1IBqBbgweM9a3NzwxCs2mNdihm1TebTPRURkeJESfpVqNEWKUEcDtj7Kyx9DU7tMI55BECHx6DlaHC++gJxGVl25vwVxX//3E9sUgYADSr58HTvOnQML1/YtRe5bmqbzKd7KiIixYmS9KtQoy1SAtntsHMeLJsEcQeMY94h0OkJaDoCnK6+QFxSehbTV0byyYqDJGdkA9C+ZgBP965Do8p+hVx5kWtT22Q+3VMRESlOlKRfhRptkRIsOwu2zoHlb0D8UeOYX1VjJfhGg8Fqu+rlcUnpfLD0AF+uO0JmtvGr7+aGITzesxbVy3sVdu1Frkhtk/l0T0VEpDhRkn4VarRFSoGsdNj0Gax8G5JOGccCa0HXf0Pd/mC9+gJxR8+k8O6SffwQcRyHA2xWC4NbhjK+ezhBPm434AOI5Ka2yXy6pyIiUpwoSb8KNdoipUhGCvz1CayeAqlnjWMVGkG3/0B4T7BcfYG43dEJvPXbXv7cEwOAm7OVUe3DeLBzDXzdnQu58iIXqW0yn+6piIgUJ0rSr0KNtkgplBYPa6fC2v9BRqJxLLS1kayHdbrm5esPxfHGoj1sjjoHgK+7Mw93rcGIttVwc776EHoRM6htMp/uqYiIFCdK0q9CjbZIKZYcZ/Sq//UpZBlbrxHWGbo/D5VbXPVSh8PBkl2neOu3veyPSQIgxNeNx3rUYkCzSjhpj3UpRGqbzKd7KiIixYmS9KtQoy1SBiSehBVvw6ZZYM80jtXqY/SsV2hw1Uuz7Q6+33yMKUv2cSI+DYCaQV482as2PesFY7nGEHqR/FDbZD7dUxERKU6UpF+FGm2RMuTsEVj+Jmz9Chx241j9AcYCc4HhV700LTObL9Ye4X/LDnAuxUj0m1Xx4+nedWhdPaCway5ljNom8+meiohIcaIk/SrUaIuUQbH7Yen/GXutA1is0HgodHka/Kpc9dL41Ew+WXGQ6asiScs0Ev2utcvzVO861A3R7xAxh9om8+meiohIcaIk/SrUaIuUYSe3w5+vwb5fjddWZ2hxL3R8HLwrXPXSmIQ03vtjP19vOEq23YHFArc1qcTDXWtQM8j7BlReSjO1TebTPRURkeJESfpVqNEWEY5ugD9fgcjlxmsnd2j9ALQfDx7+V700MjaZtxfvZcG26JxjdSp4069xRW5uGEK1QM9CrLiUVmqbzKd7KiIixYmS9KtQoy0iOQ4tN5L1YxuM164+0PZhaPMQuF3998O2Y+d4/4/9LNt7miz7xV+j9Sv6cEsjI2GvEuBRmLWXUkRtk/l0T0VEpDhRkn4VarRFJBeHA/b9Bn++Cqe2G8fc/aHDeGh5P7hcPdE+l5LBbztP8su2aNYcjCP7bwl7o8q+3NIohL4NQ6hcTgm7XJnaJvPpnoqISHGiJP0q1GiLyGXZ7bDrR2OBubj9xjGvYOj0JDS7B5xcrhkiLimd33aeYsH2E6w9GMff8nWaVvHj5oZGwl7Rz71wPoOUWGqbzKd7KiIixYmS9KtQoy0iV5WdBdu+geWvw7ko45hvFWMl+EZDwOZ0XWFOJ6azaOdJFmw7wfrIM/z9N22LquW4+XwPe7CPWyF8CClp1DaZT/dURESKEyXpV6FGW0SuS1YGbP4MVrwNSSeNYwHh0HUi1LsdrNbrDhWTkMavO06yYFs0G45cTNgtFmhZzZ9bGoXQu0EFgryVsJdVapvMp3sqIiLFiZL0q1CjLSJ5kpECG6bBqnch9YxxLLghdHsWavU2Mu08OBmfxsLt0SzYHs2mI2dzjlst0DosgJsbhdCnQQUCvFzN/BRSzKltMp/uqYiIFCdK0q9CjbaI5EtaAqz7ENZ+AOkJxrHKLaHjE1Czx3UPg/+74+dS+XV7NL9siybi6Lmc4zarhbbVjYS9d/0KlPO89nx4KdnUNplP91RERIoTJelXoUZbRAok5Qysfg/WfwxZqcYx74rQdBg0vRvKVctX2KNnUnJ62Lcdi885brNaaF8zkFsahdCrXgV8PZxN+BBS3KhtMp/uqYiIFCdK0q9CjbaImCLxFKx5HyK+ujgMHqB6F2g2AurcAk75G7J+JC6ZBdujWbAtmp0nEnKOO9ssdKgZyC2NKnJT/WB83JSwlxZqm8yneyoiIsWJkvSrUKMtIqbKSoc9C2Dz53Bo6cXj7v7Q+C5oNhyC6uY7/KHTSSw8PyR+z8nEnOMuNiudahkJe/e6QXgrYS/R1DaZT/dURESKEyXpV6FGW0QKzdnDsGU2bPkSEk9cPF65ldG7Xv92cPXKd/gDMYks2HaSX7adYH9MUs5xFycrXWuX5+ZGFeleJwhP17zPj5eiVRbapqlTp/LWW28RHR1N/fr1mTJlCh07drzsufPmzePDDz8kIiKC9PR06tevz4svvkivXr2uu7yycE9FRKTkyEu7dP17CBWSqVOnEhYWhpubG82bN2flypVXPHfevHncdNNNlC9fHh8fH9q2bctvv/12A2srInIV5aoZq76P3w5DvzWGvFtscOwvmD8WJteG+ePg2CbIx/ejNYO8ebRHOEsmdGbxY50Y1z2c6uU9yciy89vOU4ybs4Xmry7hodmbWLAtmpSMLPM/o0g+fPPNN4wfP55nn32WLVu20LFjR/r06UNUVNRlz1+xYgU33XQTCxcuZNOmTXTt2pV+/fqxZcuWG1xzERGRG69Ie9K/+eYbhg8fztSpU2nfvj0ff/wx06ZNY9euXVSpUuWS88ePH0/FihXp2rUrfn5+zJw5k7fffpv169fTtGnT6ypT36yLyA2VeAq2fmUMhz9z6OLxoPpG73qjO8HDP9/hHQ4He04msmBbNL9sO8HhuJSc99ydbXSvG8QtjULoUjsIN2dbQT6JFKLS3ja1bt2aZs2a8eGHH+Ycq1u3LrfddhuTJk26rhj169dn8ODBPP/889d1fmm/pyIiUrKUmOHuarRFpMxwOODIaiNZ3/UTZKUZx22uUO9WI2Gv2gGs+R/g5HA42HkigQXbjYT96JnUnPc8XWx0CA+kS+0gutQuT4ive0E/kZioNLdNGRkZeHh4MHfuXG6//fac448++igREREsX778mjHsdjvVqlXjqaeeYuzYsZc9Jz09nfT09JzXCQkJhIaGlsp7KiIiJU9e2voim7iYkZHBpk2beOaZZ3Id79mzJ2vWrLmuGHa7ncTERPz9r9wLdblGW0TkhrNYoFoH49HnDdj+HWz6DE5th+1zjUe5MGOhucZDwSckH0VYaFDJlwaVfHmqV222H48/38MezfFzqfy28xS/7TwFQJ0K3jkJe/Oq5XC2FfnsJymlYmNjyc7OJjg4ONfx4OBgTp48eV0xJk+eTHJyMnfeeecVz5k0aRIvvfRSgeoqIiJSHBRZkq5GW0TKLPdy0Op+aDkaoiOM3vVtc+FsJPzxMvz5GtTqZfSu17wJbHn/VW2xWGhU2Y9Glf14pk8dth+PZ9ne0yzbG8OWo+fYczKRPScT+Wj5Qbxdnc73spenS+0ggn3czP/MUuZZLJZcrx0OxyXHLmfOnDm8+OKL/PTTTwQFBV3xvIkTJzJhwoSc1xd60kVEREqaIl8CWI22iJRZFgtUbGo8er5qDIPf/DlErYW9C42HVwVoOgya3g3+1fNZzMWEfVz3cM4mZ7Bi/2mW7T3N8n2nOZOcwa87TvLrDuML0rohPnQ9n7A3q+KHk3rZpQACAwOx2WyXfAEfExNzyRf1//TNN99w3333MXfuXHr06HHVc11dXXF1dS1wfUVERIpakSXparRFRP7GxROaDDUep/cayfrWOZB0ElZONh5hnaDZPcaq8c757+0u5+lC/yaV6N+kEna7g23H41m2N4Zle0+z9dg5dkcnsDs6ganLDuLt5kSn8PJ0rl2eLrXKE6RedskjFxcXmjdvzpIlS3LNSV+yZAn9+/e/4nVz5sxh1KhRzJkzh5tvvvlGVFVERKRYKPKF45o3b87UqVNzjtWrV4/+/ftfceG4vzfat912W57LLM2L84hIKZOVYfSmb/4cDv4JnP917V4OGg0x5q8H1ze1yLikdFbuj2Xp3hhW7DvN2ZTMXO/Xr+hD1/Nz2ZuEqpfdLKW9bbqwm8tHH31E27Zt+eSTT/j000/ZuXMnVatWZeLEiRw/fpzPP/8cMNr6ESNG8N577zFgwICcOO7u7vj6+l5XmaX9noqISMlSYlZ3V6MtInKdzkXBltmw5UtIOHbxeKUWxtz1BgPA1dvUIrPtDrYeO5czl33bsfhc7/u6O9Px/IrxnWuVp7y3Ri3lV1lom6ZOncqbb75JdHQ0DRo04N1336VTp04AjBw5ksOHD7Ns2TIAunTpctlV3++55x5mzZp1XeWVhXsqIiIlR4lJ0kGNtohIntiz4eBS2PyZ0ctuzzKOO3saiXqze6ByC2O+u8lOJ6azYt9plu07zYp9p4lPzd3L3rCSL11rl6dz7SCahPphs5pfh9JKbZP5dE9FRKQ4KVFJ+o2mRltESo2kGNj6tTEcPm7/xePl6xq9642HgMeVt6gsiKxse04v+9K9Mew4nnt7Sz8PZzqFl6dL7fJ0rlWeAC/1sl+N2ibz6Z6KiEhxoiT9KtRoi0ip43BA1Dqjd33nj5CVahy3uUDdfkbCXq0TWAtv/nhMYhrL917sZU9My8p5z2KBRpV8c/Zlb1RZvez/pLbJfLqnIiJSnChJvwo12iJSqqWegx3fGb3r0VsvHvepDD4VweoEVhvYnM8//8fD5my8b3UCq3O+zs/GyqGzGWw7kcTW40kcPJNONjayHFaycMLDzYUmVQNpHhZE8+pB+Hm65Y7v4lWg1etLIrVN5ruee5qdnU1mZuZl3xMBsNlsODk5Xdf2wCIiV5OXtr7I90kXERETuftBy9HG40QEbPkCts01Fpv7+4JzhcgGhJ9/DARw+ccJDuDw+cfSywSwOkHlllC9C1TvCpWaGUm8iImSkpI4duwYZayvQvLBw8ODkJAQXFz++ctMRKRwqCddRKS0y0iBo+sgM9VYaC4701iAzp4F9szzP7PPH8/K/cj+2/v2v72fnXXpudcR22HPIiMjg8zMDLKyMrHas7CRjdP5h81yaZOU5eRJaqW2WGt0w712d6xBtQtlYbyipLbJfFe7p9nZ2ezfvx8PDw/Kly+vXlK5LIfDQUZGBqdPnyY7O5vw8HCshThtSERKN/Wki4jIRS4eUKNbUdcCAAvgev4BEB2fasxl33uaVQdiSU7LoLLlNB2sO2hv3UF7607KZSXhfeR3OPI7/Akx+LPNtSmHvFtyKqAN7v4VKe/tSnlvV4LO/yzv7YqHi5o4ubzMzEwcDgfly5fH3d29qKsjxZi7uzvOzs4cOXKEjIwM3NzK1lQcESka+gtGRESKTIivO0NaVWFIqypkZNnZeOQMu04kcDqxLX8mpvNtYire53ZTK3kjzbMiaGndR5DlDD3S/4D0PyAW9thDWW1vwLf2Bvxlr0sKxh/Rni6284m7W07iXt7blfJerpT3MX4Gebvi7+mCk029Y2WRetDleqj3XERuNCXpIiJSLLg4WWlXI5B2NQL/8U5bYBSZ2XbizsWTcmA11shl+JxYRbmEPdSxHqWO9Sj38StZ2NjiCGdFVgNWZzZga1wNDselXLVciwUCPF0ofyGZ93K9bM98eW9XvF21gJSIiIgULiXpIiJSIjjbrFQIKAcBt0DrW4yDyXEQuRwOLYNDS3E6F0VLyx5aOu/hcb4jy9mb2MBWHPZpyQ63ZuzNDOZ0cgYxCemcTkonLikduwNikzKITcpgd/TV6+DmbL0kkX+xX331xIuIiIhplKSLiEjJ5RkADQYYD4cDzkYaCfvBpRC5Aqe0c1SI/oMK0X/QBsCnkrFqfPOuUL0z2R7lOZOcwenEdGIS0zidaCTvpxPTzx9LJ/b888T0LNIy7Rw9k8rRM8Ze9B4uNl69rWER3gAREREpbZSki4hI6WCxgH9149FilLGqfPRWOLTUSNyj1kHCcYiYbTwAW1B9ytfoSvnqXagX1g5cgq4YPjUjm9gkI3E/fT6hT8+y36APJyIiImWFknQRESmdrDZjj/VKzaDj48ZWdFFrc4bGc3I7xOw0Hms/AKszhLY2etprdIWQJmC72Ey6u9gI9fcg1N+jqD6RSLGTmZmJs7NzUVdDRKRU0SQ6EREpG1w8oGZ36PkKjFkFTx6EO2ZA0+HgG2rs635kFSx9FaZ1hzerw9fD4K9PIfaAMZxeSiWHw0FKRlaRPBx5/He1aNEiOnTogJ+fHwEBAdxyyy0cPHgw5/1jx44xZMgQ/P398fT0pEWLFqxfvz7n/fnz59OiRQvc3NwIDAxkwIABOe9ZLBZ+/PHHXOX5+fkxa9YsAA4fPozFYuHbb7+lS5cuuLm58eWXXxIXF8ddd91F5cqV8fDwoGHDhsyZMydXHLvdzhtvvEHNmjVxdXWlSpUqvPbaawB069aNsWPH5jo/Li4OV1dX/vzzzzzdHxGR0kA96SIiUjZ5BkKDgcbD4YAzhy4OjY9cAWnxsOcX4wHgUxlqdIHqXSGsM3iVL8rai4lSM7Op9/xvRVL2rpd74eFy/X+OJScnM2HCBBo2bEhycjLPP/88t99+OxEREaSkpNC5c2cqVarE/PnzqVChAps3b8ZuN6ZlLFiwgAEDBvDss8/yxRdfkJGRwYIFC/Jc56effprJkyczc+ZMXF1dSUtLo3nz5jz99NP4+PiwYMEChg8fTvXq1WndujUAEydO5NNPP+Xdd9+lQ4cOREdHs2fPHgBGjx7N2LFjmTx5Mq6urgDMnj2bihUr0rVr1zzXT0SkpFOSLiIiYrFAQA3j0XK0MZ/9RMQ/5rMfgy1fGg+A4IZQvTN0fgrcfIuy9lKGDBw4MNfr6dOnExQUxK5du1izZg2nT59mw4YN+Pv7A1CzZs2cc1977TWGDBnCSy+9lHOscePGea7D+PHjc/XAAzzxxBM5zx955BEWLVrE3Llzad26NYmJibz33nt88MEH3HPPPQDUqFGDDh065HymRx55hJ9++ok777wTgJkzZzJy5EhteSgiZZKSdBERkX+y2qByc+PR6QnISDbmsx9cCoeWw6ntxuPsYejxYlHXVgrI3dnGrpd7FVnZeXHw4EGee+451q1bR2xsbE4veVRUFBERETRt2jQnQf+niIgI7r///gLXuUWLFrleZ2dn8/rrr/PNN99w/Phx0tPTSU9Px9PTE4Ddu3eTnp5O9+7dLxvP1dWVu+++mxkzZnDnnXcSERHB1q1bLxl6LyJSVihJFxERuRYXT6jZw3gAJMUYQ+KTY8GmRbNKOovFkqch50WpX79+hIaG8umnn1KxYkXsdjsNGjQgIyMDd3f3q157rfctFsslc+QzMzMvOe9C8n3B5MmTeffdd5kyZQoNGzbE09OT8ePHk5GRcV3lgjHkvUmTJhw7dowZM2bQvXt3qlates3rRERKIy0cJyIikldeQdDwDmgzpqhrImVIXFwcu3fv5j//+Q/du3enbt26nD17Nuf9Ro0aERERwZkzZy57faNGjfjjjz+uGL98+fJER0fnvN6/fz8pKSnXrNfKlSvp378/d999N40bN6Z69ers378/5/3w8HDc3d2vWnbDhg1p0aIFn376KV999RWjRo26ZrkiIqWVknQRERGREqBcuXIEBATwySefcODAAf78808mTJiQ8/5dd91FhQoVuO2221i9ejWHDh3i+++/Z+3atQC88MILzJkzhxdeeIHdu3ezfft23nzzzZzru3XrxgcffMDmzZvZuHEjY8aMua7t1WrWrMmSJUtYs2YNu3fv5sEHH+TkyZM577u5ufH000/z1FNP8fnnn3Pw4EHWrVvH9OnTc8UZPXo0r7/+OtnZ2dx+++0FvV0iIiWWknQRERGREsBqtfL111+zadMmGjRowGOPPcZbb72V876LiwuLFy8mKCiIvn370rBhQ15//XVsNmPee5cuXZg7dy7z58+nSZMmdOvWLdf2bJMnTyY0NJROnToxdOhQnnjiCTw8PK5Zr+eee45mzZrRq1cvunTpkvNFwT/Pefzxx3n++eepW7cugwcPJiYmJtc5d911F05OTgwdOhQ3N7cC3CkRkZLN4sjrBp0lXEJCAr6+vsTHx+Pj41PU1REREVHbVAiudk/T0tKIjIwkLCxMyWAxcvToUapVq8aGDRto1qxZUVcnh/69iIgZ8tLWl4xVUkRERESkVMrMzCQ6OppnnnmGNm3aFKsEXUSkKGi4u4iIiIgUmdWrV1O1alU2bdrERx99VNTVEREpcupJFxEREZEi06VLl0u2fhMRKcvUky4iIiIiIiJSTChJFxERERERESkmlKSLiIiIiIiIFBNK0kVERERERESKCSXpIiIiIiIiIsWEknQRERERERGRYkJJuoiIiEgZUK1aNaZMmVLU1RARkWtQki4iIiIiIiJSTChJFxEREZFiLTs7G7vdXtTVEBG5IZSki4iISNnmcEBGctE8HI7rquLHH39MpUqVLklUb731Vu655x4OHjxI//79CQ4OxsvLi5YtW/L777/n+5a88847NGzYEE9PT0JDQ3nooYdISkrKdc7q1avp3LkzHh4elCtXjl69enH27FkA7HY7b7zxBjVr1sTV1ZUqVarw2muvAbBs2TIsFgvnzp3LiRUREYHFYuHw4cMAzJo1Cz8/P3755Rfq1auHq6srR44cYcOGDdx0000EBgbi6+tL586d2bx5c656nTt3jgceeIDg4GDc3Nxo0KABv/zyC8nJyfj4+PDdd9/lOv/nn3/G09OTxMTEfN8vEREzORV1BURERESKVGYK/F/Foin73yfAxfOapw0aNIhx48axdOlSunfvDsDZs2f57bff+Pnnn0lKSqJv3768+uqruLm58dlnn9GvXz/27t1LlSpV8lwtq9XK+++/T7Vq1YiMjOShhx7iqaeeYurUqYCRVHfv3p1Ro0bx/vvv4+TkxNKlS8nOzgZg4sSJfPrpp7z77rt06NCB6Oho9uzZk6c6pKSkMGnSJKZNm0ZAQABBQUFERkZyzz338P777wMwefJk+vbty/79+/H29sZut9OnTx8SExP58ssvqVGjBrt27cJms+Hp6cmQIUOYOXMmd9xxR045F157e3vn+T6JiBQGJekiIiIixZy/vz+9e/fmq6++yknS586di7+/P927d8dms9G4ceOc81999VV++OEH5s+fz9ixY/Nc3vjx43Oeh4WF8corr/Cvf/0rJ0l/8803adGiRc5rgPr16wOQmJjIe++9xwcffMA999wDQI0aNejQoUOe6pCZmcnUqVNzfa5u3brlOufjjz+mXLlyLF++nFtuuYXff/+dv/76i927d1OrVi0AqlevnnP+6NGjadeuHSdOnKBixYrExsbyyy+/sGTJkjzVTUSkMClJFxERkbLN2cPo0S6qsq/TsGHDeOCBB5g6dSqurq7Mnj2bIUOGYLPZSE5O5qWXXuKXX37hxIkTZGVlkZqaSlRUVL6qtXTpUv7v//6PXbt2kZCQQFZWFmlpaSQnJ+Pp6UlERASDBg267LW7d+8mPT0958uE/HJxcaFRo0a5jsXExPD888/z559/curUKbKzs0lJScn5nBEREVSuXDknQf+nVq1aUb9+fT7//HOeeeYZvvjiC6pUqUKnTp0KVFcRETNpTrqIiIiUbRaLMeS8KB4Wy3VXs1+/ftjtdhYsWMDRo0dZuXIld999NwBPPvkk33//Pa+99horV64kIiKChg0bkpGRkefbceTIEfr27UuDBg34/vvv2bRpE//73/8Ao3cbwN3d/YrXX+09MIbSAzj+Nh//Qtx/xrH84/6MHDmSTZs2MWXKFNasWUNERAQBAQE5n/NaZYPRmz5z5kzAGOp+7733XlKOiEhRUpIuIiIiUgK4u7szYMAAZs+ezZw5c6hVqxbNmzcHYOXKlYwcOZLbb7+dhg0bUqFChZxF2PJq48aNZGVlMXnyZNq0aUOtWrU4cSL3SINGjRrxxx9/XPb68PBw3N3dr/h++fLlAYiOjs45FhERcV11W7lyJePGjaNv377Ur18fV1dXYmNjc9Xr2LFj7Nu374ox7r77bqKionj//ffZuXNnzpB8EZHiQkm6iIiISAkxbNgwFixYwIwZM3J60QFq1qzJvHnziIiIYOvWrQwdOjTfW5bVqFGDrKws/vvf/3Lo0CG++OILPvroo1znTJw4kQ0bNvDQQw+xbds29uzZw4cffkhsbCxubm48/fTTPPXUU3z++eccPHiQdevWMX369Jy6hoaG8uKLL7Jv3z4WLFjA5MmTr6tuNWvW5IsvvmD37t2sX7+eYcOG5eo979y5M506dWLgwIEsWbKEyMhIfv31VxYtWpRzTrly5RgwYABPPvkkPXv2pHLlyvm6TyIihUVJuoiIiEgJ0a1bN/z9/dm7dy9Dhw7NOf7uu+9Srlw52rVrR79+/ejVqxfNmjXLVxlNmjThnXfe4Y033qBBgwbMnj2bSZMm5TqnVq1aLF68mK1bt9KqVSvatm3LTz/9hJOTsdzRc889x+OPP87zzz9P3bp1GTx4MDExMQA4OzszZ84c9uzZQ+PGjXnjjTd49dVXr6tuM2bM4OzZszRt2pThw4czbtw4goKCcp3z/fff07JlS+666y7q1avHU089lbPq/AX33XcfGRkZjBo1Kl/3SESkMFkcjuvcoLOUSEhIwNfXl/j4eHx8fIq6OiIiImqbCsHV7mlaWhqRkZGEhYXh5uZWRDWUojR79mweffRRTpw4gYuLy1XP1b8XETFDXtp6re4uIiIiImVCSkoKkZGRTJo0iQcffPCaCbqISFHQcHcRERGRMmT27Nl4eXld9nFhr/PS6s0336RJkyYEBwczceLEoq6OiMhlqSddREREpAy59dZbad269WXfc3Z2vsG1ubFefPFFXnzxxaKuhojIVSlJFxERESlDvL298fb2LupqiIjIFWi4u4iIiJRJZWztXMkn/TsRkRtNSbqIiIiUKTabDYCMjIwiromUBCkpKUDpnwogIsWHhruLiIhImeLk5ISHhwenT5/G2dkZq1V9FnIph8NBSkoKMTEx+Pn55Xy5IyJS2JSki4iISJlisVgICQkhMjKSI0eOFHV1pJjz8/OjQoUKRV0NESlDlKSLiIhImePi4kJ4eLiGvMtVOTs7qwddRG44JekiIiJSJlmtVtzc3Iq6GiIiIrkU+SSsqVOnEhYWhpubG82bN2flypVXPX/58uU0b94cNzc3qlevzkcffXSDaioiIiL5pfZeRETk+hRpkv7NN98wfvx4nn32WbZs2ULHjh3p06cPUVFRlz0/MjKSvn370rFjR7Zs2cK///1vxo0bx/fff3+Day4iIiLXS+29iIjI9bM4inDzx9atW9OsWTM+/PDDnGN169bltttuY9KkSZec//TTTzN//nx2796dc2zMmDFs3bqVtWvXXleZCQkJ+Pr6Eh8fj4+PT8E/hIiISAGV9rZJ7b2IiJR1eWmXimxOekZGBps2beKZZ57Jdbxnz56sWbPmstesXbuWnj175jrWq1cvpk+fTmZm5mX3r0xPTyc9PT3ndXx8PGDcJBERkeLgQptUhN+bFxq19yIiInlr64ssSY+NjSU7O5vg4OBcx4ODgzl58uRlrzl58uRlz8/KyiI2NpaQkJBLrpk0aRIvvfTSJcdDQ0MLUHsRERHzJSYm4uvrW9TVMJXaexERkYuup60v8tXdLRZLrtcOh+OSY9c6/3LHL5g4cSITJkzIeW232zlz5gwBAQFXLed6JSQkEBoaytGjRzWcziS6p+bTPS0cuq/mK6v31OFwkJiYSMWKFYu6KoWmJLf3ZfXfZWHSPS0cuq/m0z01X1m9p3lp64ssSQ8MDMRms13yLXpMTMwl355fUKFChcue7+TkREBAwGWvcXV1xdXVNdcxPz+//Ff8Cnx8fMrUP7IbQffUfLqnhUP31Xxl8Z6Wth70C0pTe18W/10WNt3TwqH7aj7dU/OVxXt6vW19ka3u7uLiQvPmzVmyZEmu40uWLKFdu3aXvaZt27aXnL948WJatGhx2flpIiIiUrTU3ouIiORNkW7BNmHCBKZNm8aMGTPYvfv/27v/mKrqP47jrwvKT1kgDIQ1EWeFQKaAcwjYysbAbKNRlkOl9YejgPgxWy5sKkvpx7Jm6nUU+kfpVPolLamIFgrE+DGvsiL9QyctZWg5Ey2YcL5/fPe9392R3y/SoXPv5fnY7nbP597Lfd0zttfe99yz06vy8nL19fWpsLBQ0r9/urZu3Trn8wsLC3XhwgVVVFSot7dX+/btU21trTZs2GDVRwAAAP8HfQ8AwPhZek76U089pV9//VVVVVW6dOmSkpKSdOzYMcXGxkqSLl265HIN1bi4OB07dkzl5eXavXu3YmJitHPnTuXl5Vn1EeTv76/NmzeP+YkdJo59aj726eRgv5qPfeqdPL3v+b80H/t0crBfzcc+NR/79P+z9DrpAAAAAADgvyz9uTsAAAAAAPgvhnQAAAAAANwEQzoAAAAAAG6CIR0AAAAAADfBkP437NmzR3FxcQoICFBKSopOnDhhdSSPVl1drcWLFyskJESRkZHKzc3VmTNnrI7lVaqrq2Wz2VRWVmZ1FI/2yy+/aM2aNQoPD1dQUJAWLlyo7u5uq2N5tFu3bmnTpk2Ki4tTYGCg5s6dq6qqKo2OjlodDVMcXW8uun7y0fXmoe/NRdePH0P6BB0+fFhlZWWqrKzUyZMnlZmZqZycHJdLyODONDc3q6ioSO3t7WpsbNStW7eUlZWlGzduWB3NK3R2dqqmpkYLFiywOopHu3r1qtLT0zV9+nQ1NDToxx9/1FtvvaXQ0FCro3m0119/XXv37tWuXbvU29urN954Q2+++abeffddq6NhCqPrzUfXTy663jz0vfno+vHjEmwTtGTJEiUnJ8tutzvX5s+fr9zcXFVXV1uYzHtcvnxZkZGRam5u1rJly6yO49EGBweVnJysPXv26NVXX9XChQv1zjvvWB3LI23cuFGtra0cTTPZypUrFRUVpdraWudaXl6egoKC9MEHH1iYDFMZXT/56Hrz0PXmou/NR9ePH0fSJ2B4eFjd3d3KyspyWc/KylJbW5tFqbzPtWvXJEkzZ860OInnKyoq0qOPPqpHHnnE6iger76+XqmpqXryyScVGRmpRYsW6b333rM6lsfLyMhQU1OTzp49K0k6deqUWlpatGLFCouTYaqi6/8ZdL156Hpz0ffmo+vHb5rVATzRlStXNDIyoqioKJf1qKgo9ff3W5TKuxiGoYqKCmVkZCgpKcnqOB7t0KFD6u7uVldXl9VRvMK5c+dkt9tVUVGhl19+WR0dHXrhhRfk7++vdevWWR3PY7300ku6du2a4uPj5evrq5GREW3btk2rV6+2OhqmKLp+8tH15qHrzUffm4+uHz+G9L/BZrO5bBuGMWYNE1NcXKzTp0+rpaXF6ige7eeff1Zpaam+/vprBQQEWB3HK4yOjio1NVXbt2+XJC1atEg//PCD7HY7pf03HD58WB9++KEOHjyoxMREORwOlZWVKSYmRgUFBVbHwxRG108eut4cdP3koO/NR9ePH0P6BERERMjX13fMN+kDAwNjvnHHnSspKVF9fb2OHz+uu+++2+o4Hq27u1sDAwNKSUlxro2MjOj48ePatWuXhoaG5Ovra2FCzxMdHa2EhASXtfnz5+vjjz+2KJF3ePHFF7Vx40Y9/fTTkqT7779fFy5cUHV1NcUNS9D1k4uuNw9dPznoe/PR9ePHOekT4Ofnp5SUFDU2NrqsNzY2aunSpRal8nyGYai4uFiffPKJvv32W8XFxVkdyeMtX75cPT09cjgczltqaqry8/PlcDgo7QlIT08fc7mgs2fPKjY21qJE3uHmzZvy8XGtJF9fXy7LAsvQ9ZODrjcfXT856Hvz0fXjx5H0CaqoqNDatWuVmpqqtLQ01dTUqK+vT4WFhVZH81hFRUU6ePCgjh49qpCQEOfRi7vuukuBgYEWp/NMISEhY87zCw4OVnh4OOf/TVB5ebmWLl2q7du3a9WqVero6FBNTY1qamqsjubRHnvsMW3btk2zZ89WYmKiTp48qR07dujZZ5+1OhqmMLrefHS9+ej6yUHfm4+uvwMGJmz37t1GbGys4efnZyQnJxvNzc1WR/Jokv7ytn//fqujeZUHH3zQKC0ttTqGR/v888+NpKQkw9/f34iPjzdqamqsjuTxfv/9d6O0tNSYPXu2ERAQYMydO9eorKw0hoaGrI6GKY6uNxdd/8+g681B35uLrh8/rpMOAAAAAICb4Jx0AAAAAADcBEM6AAAAAABugiEdAAAAAAA3wZAOAAAAAICbYEgHAAAAAMBNMKQDAAAAAOAmGNIBAAAAAHATDOkAAAAAALgJhnQAprPZbPrss8+sjgEAACYRfQ9MDoZ0wIs888wzstlsY27Z2dlWR7sjnZ2diomJkSRdvHhRgYGBGh4etjgVAADugb4HvNs0qwMAMFd2drb279/vsubv729Rmon5/vvvlZ6eLkk6ceKEUlNT5efnZ3EqAADcB30PeC+OpANext/fX7NmzXK5hYWFOR+32Wyy2+3KyclRYGCg4uLiVFdX5/I3enp69PDDDyswMFDh4eFav369BgcHXZ6zb98+JSYmyt/fX9HR0SouLnZ5/MqVK3r88ccVFBSke+65R/X19eP+DG1tbc7Sbmlpcd4HAAD/Rt8D3oshHZiCXnnlFeXl5enUqVNas2aNVq9erd7eXknSzZs3lZ2drbCwMHV2dqqurk7ffPONSynb7XYVFRVp/fr16unpUX19vebNm+fyHlu3btWqVat0+vRprVixQvn5+frtt99um6mlpUWhoaEKDQ3VRx99pMrKSoWGhmrv3r3auXOnQkND9dprr03ODgEAwAvR94CHMgB4jYKCAsPX19cIDg52uVVVVTmfI8koLCx0ed2SJUuM5557zjAMw6ipqTHCwsKMwcFB5+NffPGF4ePjY/T39xuGYRgxMTFGZWXlbXNIMjZt2uTcHhwcNGw2m9HQ0HDb1/zxxx/G+fPnjYaGBiMsLMw4d+6c0dXVZfj5+Rm9vb3G+fPnjatXr97R/gAAwBvR94B345x0wMs89NBDstvtLmszZ8502U5LSxuz7XA4JEm9vb164IEHFBwc7Hw8PT1do6OjOnPmjGw2my5evKjly5f/zxwLFixw3g8ODlZISIgGBgZu+/yAgADNmTNHR44cUU5OjuLi4tTW1qbMzEzFx8f/z/cCAGCqoe8B78WQDniZ4ODgMT9FGw+bzSZJMgzDef+vnhMYGDiuvzd9+vQxrx0dHb3t82fMmCFJGhoako+Pj44eParh4WEZhqEZM2YoMzNTDQ0N43pvAAC8HX0PeC/OSQemoPb29jHb//n2OiEhQQ6HQzdu3HA+3traKh8fH917770KCQnRnDlz1NTUZGomh8Ohrq4u+fr6qqmpSQ6HQ+Hh4Tpy5IgcDofef/99U98PAABvR98Dnokj6YCXGRoaUn9/v8vatGnTFBER4dyuq6tTamqqMjIydODAAXV0dKi2tlaSlJ+fr82bN6ugoEBbtmzR5cuXVVJSorVr1yoqKkqStGXLFhUWFioyMlI5OTm6fv26WltbVVJSMuHc8+bNU3t7u6KiopSRkaG+vj5dv35dK1euHPMtPQAAUx19D3gvhnTAy3z55ZeKjo52Wbvvvvv0008/Obe3bt2qQ4cO6fnnn9esWbN04MABJSQkSJKCgoL01VdfqbS0VIsXL1ZQUJDy8vK0Y8cO5+sLCgr0559/6u2339aGDRsUERGhJ5544m9n/+6777Rs2TJJUnNzs9LS0ihsAAD+An0PeC+bYRiG1SEA/HNsNps+/fRT5ebmWh0FAABMEvoe8Fyckw4AAAAAgJtgSAcAAAAAwE3wc3cAAAAAANwER9IBAAAAAHATDOkAAAAAALgJhnQAAAAAANwEQzoAAAAAAG6CIR0AAAAAADfBkA4AAAAAgJtgSAcAAAAAwE0wpAMAAAAA4Cb+Bc7D+DtEr0qlAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "matplotlib.rc_file_defaults()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,4))\n",
    "\n",
    "ax1.plot(history.history['loss'], label='loss')\n",
    "ax1.plot(history.history['val_loss'], label='val_loss')\n",
    "ax1.set_ylim([0, max(plt.ylim())])\n",
    "ax1.set_xlabel('Epoch #')\n",
    "ax1.set_ylabel('CE/token')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(history.history['masked_acc'], label='accuracy')\n",
    "ax2.plot(history.history['val_masked_acc'], label='val_accuracy')\n",
    "ax2.set_ylim([0, max(plt.ylim())])\n",
    "ax2.set_xlabel('Epoch #')\n",
    "ax2.set_ylabel('CE/token')\n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a>\n",
    "# 6 - Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Address-Auto-Complete bot `model` training is completed with 96% accuracy on the validation dataframe with 10 epochs. In this section, we run model inferences on some real-world addresses to examine the model output and its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############################################\n",
      "Case 1\n",
      "\n",
      "Context str: b'39 109 Ave Jamaica 11435'\n",
      "\n",
      "Inference result from Address-Auto-Complete bot: 39 109 ave jamaica queens ny 11435 \n",
      "\n",
      "Original raw str: b'39 109 Ave Jamaica Queens NY 11435'\n",
      "###############################################\n",
      "###############################################\n",
      "Case 2\n",
      "\n",
      "Context str: b'520 37 St Brooklyn NY'\n",
      "\n",
      "Inference result from Address-Auto-Complete bot: 520 37 st brooklyn kings ny 11232 \n",
      "\n",
      "Original raw str: b'520 37 St Brooklyn Kings NY 11203'\n",
      "###############################################\n",
      "###############################################\n",
      "Case 3\n",
      "\n",
      "Context str: b'550 Leonard St Brooklyn Kings'\n",
      "\n",
      "Inference result from Address-Auto-Complete bot: 550 leonard st brooklyn kings ny 11222 \n",
      "\n",
      "Original raw str: b'550 Leonard St Brooklyn Kings NY 11222'\n",
      "###############################################\n",
      "###############################################\n",
      "Case 4\n",
      "\n",
      "Context str: b'518 3 Ave New York 10016'\n",
      "\n",
      "Inference result from Address-Auto-Complete bot: 518 3 ave new york new york ny 10016 \n",
      "\n",
      "Original raw str: b'518 3 Ave New York New York NY 10016'\n",
      "###############################################\n",
      "###############################################\n",
      "Case 5\n",
      "\n",
      "Context str: b'2 79 New York New York 10075'\n",
      "\n",
      "Inference result from Address-Auto-Complete bot: 2 79 st new york new york ny 10075 \n",
      "\n",
      "Original raw str: b'2 79 St New York New York NY 10075'\n",
      "###############################################\n"
     ]
    }
   ],
   "source": [
    "# Generate masked addresses from the validation dataset\n",
    "for example_context_strings, example_target_strings in val_raw.take(1):\n",
    "    context_l = example_context_strings[0:5].numpy().tolist()\n",
    "    raw_l = example_target_strings[0:5].numpy().tolist()\n",
    "\n",
    "# Perform Inference. All cases seem to be correct\n",
    "for i in range(5):\n",
    "    print('###############################################')\n",
    "    print(f'Case {i+1}\\n')\n",
    "    print(f'Context str: {context_l[i]}\\n')\n",
    "\n",
    "    context_raw = context_l[i]\n",
    "    result = model.Addressor_fix([context_raw]) \n",
    "\n",
    "    print(f'Inference result from Address-Auto-Complete bot: {result.numpy()[0].decode()}\\n')\n",
    "\n",
    "    print(f'Original raw str: {raw_l[i]}')\n",
    "    print('###############################################')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6-1\"></a>\n",
    "## 6-1 - Deep Dive\n",
    "\n",
    "We asked the Address Auto Complete bot to perform the function of both *Detect Address Error* and *Auto Complete Address*. \n",
    "\n",
    "Let's use the address `49 Clinton St New York NY 10002` as an example for our demonstration. Why this address? Because I liked this LES restaurant [Yopparai](https://maps.app.goo.gl/NqEAyHaA3Ay3qE2q9) - I just went there for dinner last weekend with friends. 100% recommended!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 clinton st new york new york ny 10002 \n",
      "\n",
      " Success!\n"
     ]
    }
   ],
   "source": [
    "#Auto Complete Address task 1: Keep street name and City name, and check if the bot can complete the rest\n",
    "context_raw = '49 Clinton St New York'\n",
    "result = model.Addressor_fix([context_raw]) \n",
    "print(result.numpy()[0].decode())\n",
    "\n",
    "print('\\n Success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 clinton st new york new york ny 10002 \n",
      "\n",
      " Success!\n"
     ]
    }
   ],
   "source": [
    "#Auto Complete Address task 2: Keep street name and Zip code, and check if the bot can complete the rest\n",
    "context_raw = '49 Clinton St 10002'\n",
    "result = model.Addressor_fix([context_raw]) \n",
    "print(result.numpy()[0].decode())\n",
    "\n",
    "print('\\n Success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 clinton st new york new york ny 10002 \n",
      "\n",
      " Success!\n"
     ]
    }
   ],
   "source": [
    "#Detect Address Error task 1: What happens if we mistype Los Angeles instead of New York\n",
    "context_raw = '49 clinton st los angeles new york ny 10002 '\n",
    "result = model.Addressor_fix([context_raw]) \n",
    "print(result.numpy()[0].decode())\n",
    "\n",
    "print('\\n Success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 [UNK] st new york new york ny 10002 \n",
      "\n",
      " Failed\n",
      " This task failed because the word \"Hiliary\" is most likely not in the text corpus, therefore we are not able tokenized it and the encoder shows it as UNKNOWN\n"
     ]
    }
   ],
   "source": [
    "#Detect Address Error task 2: What happends if the street name was Hiliary instead of Clinton?\n",
    "context_raw = '49 hiliary st new york new york ny 10002 '\n",
    "result = model.Addressor_fix([context_raw]) \n",
    "print(result.numpy()[0].decode())\n",
    "\n",
    "print('\\n Failed\\n This task failed because the word \"Hiliary\" is most likely not in the text corpus, therefore we are not able tokenized it and the encoder shows it as UNKNOWN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
